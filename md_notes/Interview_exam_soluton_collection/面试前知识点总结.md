#   一.  FTP/TFTP/NFS

> 1.***FTP的传输模式*：ASCII传输模式和二进制传输模式。**

**ASCII传输模式**： 假定用户正在拷贝的文件包含的简单ASCII码文本，如果在远程机器上运行的不是UNIX，当文件传输时ftp通常会自动地调整文件的内容以便于把文件解释成另外那台计算机存储文本文件的格式。但是常常有这样的情况，用户正在传输的文件包含的不是文本文件，它们可能是程序，数据库，字处理文件或者压缩文件（尽管字处理文件包含的大部分是文本，其中也包含有指示页尺寸，字库等信息的非打印符）。在拷贝任何非文本文件之前，用binary 命令告诉ftp逐字拷贝，不要对这些文件进行处理，这也是下面要讲的二进制传输。 

**二进制传输模式**： 在二进制传输中，保存文件的位序，以便原始和拷贝的是逐位一一对应的。即使目的地机器上包含位序列的文件是没意义的。 如果两台通讯的机器为同一类型，则可优先使用二进制拷贝。



> 2.**FTP的工作方式： Standard (也就是 PORT方式，主动方式)和 Passive (也就是PASV，被动方式)** 

**主动方式**： Port模式FTP 客户端首先和FTP服务器的TCP  21端口建立连接，通过这个通道发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。  PORT命令包含了客户端用什么端口接收数据。在传送数据的时候，服务器端通过自己的TCP 20端口连接至客户端的指定端口发送数据。 FTP  server必须和客户端建立一个新的连接用来传送数据。 

**被动方式**： Passive模式在建立控制通道的时候和Standard模式类似，但建立连接后发送的不是Port命令，而是Pasv命令。FTP服务器收到Pasv命令后，随机打开一个高端端口（端口号大于1024）并且通知客户端在这个端口上传送数据的请求，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口进行数据的传送，这个时候FTP server不再需要建立一个新的和客户端之间的连接 

**请注意**: PORT模式建立数据传输通道是由服务器端发起的，服务器使用20端口连接客户端的某一个大于1024的端口；在PASV模式中，数据传输的通道的建立是由FTP客户端发起的，他使用一个大于1024的端口连接服务器的1024以上的某一个端口。  在FTP客户连接服务器的整个过程中，控制信道是一直保持连接的，而数据传输通道是临时建立的。  



> 3.**TFTP工作原理**

**建立连接**：默认情况下，作为 TFTP 服务器的主机 A 会监听 69 端口，当作为客户端的主机 B 想要下载或上传文件时，会向主机 A 的 69 端口发送包含读文件（下载）请求或写文件（上传）请求的数据包。主机 A 收到读写请求后，会打开另外一个随机的端口，通过这个端口向主机 B 发送确认包、数据包或者错误包。

**下载**：客户端向服务器的 69 端口（通常情况下）发送一个读请求，服务器收到这个读请求以后，会打开另外一个随机的端口（假设端口号是 59509），然后在它默认的路径下寻找这个文件，找到这个文件以后，每次读入文件的 512 个字节，通过端口 59509 将这 512 个字节放入数据包中发送给客户端，数据包中还包含了操作码和数据块的编号，块编号从 1 开始计数；客户端收到数据包以后，会向服务器的 59509 端口发送一个确认包，里面包含了它收到的数据包的块编号；服务器收到确认包以后，继续发送文件的下一个 512 个字节。如此循环往复，直到文件的末尾，最后一个数据包的数据块的大小会小于 512 个字节，这时服务器就认为传输已经结束，等他接收到这最后一个数据包的确认包之后就会主动关闭连接。而客户端收到这个小于 512 个字节的数据包后也认为传输已经结束，发送完确认包之后也会关闭连接。也许会有一种极端情况，就是文件的大小正好是 512 字节的倍数，这样的话，最后一个数据包的大小也是 512 个字节，这时服务器发送完包含文件数据的数据包以后，还会额外发送一个包含 0 字节的数据包，作为最后一个数据包，这样就可以保证客户端收到的最后一个数据包的大小总是小于 512 个字节的。也就是说，对于客户端而言，只要它收到的数据包的大小小于 512 个字节，它就认为传输已经结束，它就会关闭连接。

**上传**：客户端向服务器的 69 端口（通常情况下）发送一个写请求，服务器收到这个写请求以后，会打开另外一个随机的端口（假设端口号是 59509），向客户端发送一个确认包，其中块编号是 0，以此来告诉客户端自己已经准备好接收文件，并且告诉客户端自己接收文件的端口号。然后客户端就开始向服务器的 59509 端口发送数据包，服务器收到数据包后向客户端发送确认包，直到整个文件发送完毕。这个过程和下载是一样的，只不过双方的角色互换了，客户端成了发数据的一方，而服务器是接收数据的一方。



> 4.**NFS工作原理**

![image-20200406105340809](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\image-20200406105340809.png)



# 二. rsync

一般企业在使用 rsync 时会配合 inotify 使用，使用 inotify 监听文件修改情况，一旦文件某些 属性改变，就通知 rsync 进行备份 

- **inotify + rsync** 方式实现数据同步
- sersync ：金山公司周洋在 inotify 软件基础上进行开发的，功能更加强大

- 工作原理：

  要利用监控服务（inotify），监控同步数据服务器目录中信息的变化

  发现目录中数据产生变化，就利用 rsync 服务推送到备份服务器上

- **inotify**：

  异步的文件系统事件监控机制，利用事件驱动机制，而无须通过诸如 cron 等的轮询机制来获取事件，

  linux 内核从 2.6.13 起支持 inotify，通过 inotify 可以监控文件系统中添加、删除，修改、移动等各种事件

```bash
max_queued_events：inotify事件队列最大长度，如值太小会出现 Event Queue Overflow  误，默认值：16384 max_user_instances：每个用户创建inotify实例最大值，默认值：128 max_user_watches：可以监视的文件数量（单进程），默认值：8192
```

```
[root@centos8 ~]#vim /etc/sysctl.conf
fs.inotify.max_queued_events=66666
fs.inotify.max_user_watches=100000  
[root@centos8 ~]#sysctl  -p
fs.inotify.max_queued_events = 66666
fs.inotify.max_user_watches = 100000
[root@centos8 ~]#cat /proc/sys/fs/inotify/*
66666
128
100000
```

**inotify-tools** 包： 

- **inotifywait**： 在被监控的文件或目录上等待特定文件系统事件（open ，close，delete 等） 发生，常用于实时同步的目录监控
- **inotifywatch**：收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计

**例:使用 inotifywait** 

```bash
#监控一次性事件
inotifywait /data
#持续前台监控
inotifywait -mrq /data
#持续后台监控，并记录日志
inotifywait -o /root/inotify.log -drq /data --timefmt "%Y-%m-%d %H:%M" --format
"%T %w%f event: %e"
#持续前台监控特定事件
inotifywait -mrq /data --timefmt "%F %H:%M" --format "%T %w%f  event: %;e" -e
create,delete,moved_to,close_write,attrib
```

**rsync 软件包**：

rsync，rsync-daemon（CentOS 8） 

服务文件：/usr/lib/systemd/system/rsyncd.service 

配置文件：/etc/rsyncd.conf 端口：873/tcp 

**rsync命令**：

```bash
#Local:  
rsync [OPTION...] SRC... [DEST]
#Access via remote shell:
Pull:
rsync [OPTION...] [USER@]HOST:SRC... [DEST]
Push:
rsync [OPTION...] SRC... [USER@]HOST:DEST
#Access via rsync daemon:
Pull:
rsync [OPTION...] [USER@]HOST::SRC... [DEST]
rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]
Push:
rsync [OPTION...] SRC... [USER@]HOST::DEST
rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST
```

rsync 有三种工作方式： 

1. 本地文件系统上实现同步。命令行语法格式为上述"Local"段的格式。
2. 本地主机使用远程 shell 和远程主机通信。命令行语法格式为上述"Access via remote shell"段的格式。
3. 本地主机通过网络套接字连接远程主机上的 rsync daemon。命令行语法格式为上述 "Access viarsync daemon"段的格式。



# 三. 防火墙

> **防火墙概念**

- 在计算机领域，防火墙(FireWall)就是基于预先定义的安全规则来监视和控制来往的 网络流量的网络安全系统。防火墙的核心是隔离，其将受信任的内部网络和不受信任的 外部网络隔离开。内部网络一般是公司的内部局域网，外部网络一般是 Internet。
- 一般防火墙工作在网络或主机边缘，对进出网络或主机的数据包基于一定的规则检查， 并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，基本上的实现都是默认 情况下关闭所有的通过型访问，只开放允许访问的策略。

>  **防火墙分类**

- 按照防火墙的保护范围，防火墙通常被分为：

  **网络防火墙**: 网络防火墙在两个或更多的网络间监控和过滤流量，运行在网络设备上。 网络防火墙保护的是防火墙某一侧的网络(一般是局域网络)。

  **主机防火墙**: 主机防火墙运行在一般的电脑主机，并控制进出这些电脑的网络流量， 主机防火墙保护的范围是当前主机。

- 从实现方式上看，防火墙被分为：

  **硬件防火墙**: 在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件实现， 如：华为，天融信 Checkpoint，NetScreen 等

  **软件防火墙**: 运行于通用硬件平台上的防火墙应用软件，ISA --> Forefront TMG

- 从工作交互的网络协议层及划分：

  **网络层防火墙**: 只可以和 OSI 模型下四层的协议交互

  **应用层防火墙**: 运行应用层防火墙的设备可以叫代理服务器或代理网关，可以与 OSI 的七层协议交互。

> **Netfilter 中的 hook 函数**

- Netfilter 在内核中选取五个位置放了五个 hook(“勾子”) function(INPUT、OUTPUT、 FORWARD、PREROUTING、POSTROUTING)，而这五个 hook function 向用户开放， 用户可以通过一个命令工具(iptables)向其写入规则，规则由信息过滤表(table)组成， 信息过滤表包含控制 IP 包处理的规则集(ruleset)，规则被分组放在(chain)上。

- **三种数据包流动方向**

  **流入本机**:PREROUTING --> INPUT–>用户空间进程

  **流出本机**:用户空间进程 -->OUTPUT–> POSTROUTING

  **转发**:PREROUTING --> FORWARD --> POSTROUTING

![iptables](https://img-blog.csdnimg.cn/2019123117471156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lvdU9vcHM=,size_16,color_FFFFFF,t_70)

 **数据包大致传输过程** :

1. 当一个网络数据包进入网卡时，数据包首先进入 PREROUTING 链，内核根据数据包目的 IP 判断是否需 要转送出去
2. 如果数据包就是进入本机的，数据包就会沿着图向下移动，到达 INPUT 链。数据包到达 INPUT 链 后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过 OUTPUT 链，然后 到达 POSTROUTING 链输出
3. 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过 FORWARD 链，然后到 达 POSTROUTING 链输出

```bash
iptables -N # 自定义一条新的规则链
iptables -E # 重命名自定义链；引用计数不为 0 的自定义链不能够被重命名，也不能被删除
iptables -X # 删除自定义的空的规则链
iptables -P # 设置默认策略；对 filter 表中的链而言，其默认策略有： 
   			# ACCEPT：接受 DROP：丢弃
iptables -vnL --line-numbers
iptables -A 
iptables -I INPUT 2 ...
iptables -D 2
iptables -R 
iptables -F # 清空指定规则
#  (1) 可以指明规则序号 (2) 可以指明规则本身
iptables -Z # 清零计数
# （iptables 的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和）
```

## iptables 扩展匹配条件

**multiport 扩展** 以离散方式定义多端口匹配 

```bash
iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp -m multiport --dports 20:22,80 -j ACCEPT
```

**iprange 扩展** 指明连续的（但一般不是整个网络）ip 地址范围 源 IP 地址范围 `[!] --src-range from[-to]` 目标 IP 地址范围 `[!] --dst-range from[-to]` 

```bash
iptables -A INPUT -d 172.16.1.100 -p tcp --dport 80 -m iprange --src-range 172.16.1.5-172.16.1.10 -j DROP
```

**mac扩展** mac 模块可以指明源 MAC 地址 

```bash
iptables -A INPUT -s 172.16.0.100 -m mac  --mac-source  00:50:56:12:34:56 -j ACCEPT
iptables -A INPUT -s 172.16.0.100  -j REJECT
```

 **string 扩展** string 扩展用于对报文中的应用层数据做字符串模式匹配检测 

```bash
iptables -A OUTPUT -p tcp --sport 80 -m string --algo bm --from 42 --string "google" -j REJECT
```

**time 扩展** 根据将报文到达的时间与指定的时间范围进行匹配 

```bash
iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP
```

**connlimit 扩展** 根据每客户端 IP 做并发连接数数量匹配可防止 Dos(Denial of Service，拒绝服务)攻击 

```bash
iptables -A INPUT -d 172.16.100.10 -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT
# --connlimit-upto #      ：连接的数量小于等于#时匹配
# --connlimit-above #     ：连接的数量大于#时匹配
```

**limit 扩展** 基于收发报文的速率做匹 令牌桶过滤器 

```bash
iptables -I INPUT -d 172.16.100.10 -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 5 -j ACCEPT
iptables -I INPUT 2 -p icmp -j REJECT
```

**state 扩展** state 扩展模块，可以根据"连接追踪机制"去检查连接的状态，较耗资源， 会消耗内存，使用 conntrack 机制：追踪本机上的请求和响应之间的关系 

- 状态类型

  `NEW`：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因此，将其 识别为第一次发出的请求

  `ESTABLISHED`：NEW 状态之后，连接追踪信息库中为其建立的条目失效之前期间内 所进行的通信状态

  `RELATED`：新发起的但与已有连接相关联的连接，如：ftp 协议中的数据连接与命令 连接之间的关系

  `INVALID`：无效的连接，如 flag 标记不正确

  `UNTRACKED`：未进行追踪的连接，如 raw 表中关闭追踪

 已经追踪到的并记录下来的连接信息库 `/proc/net/nf_conntrack` 

 调整连接追踪功能所能够容纳的最大连接数量 `/proc/sys/net/netfilter/nf_conntrack_max` 

 查看连接跟踪有多少条目 `/proc/sys/net/netfilter/nf_conntrack_count` 

 不同的协议的连接追踪时长 `/proc/sys/net/netfilter/nf_conntrack_generic_timeout` 

 **state 模块使用格式** :

```bash
iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT
iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT
```

 **开放被动模式的 ftp 服务** :

1.  装载 ftp 连接追踪的专用模块： 跟踪模块路径：/lib/modules/kernelversion/kernel/net/netfilter1 

```bash
vim /etc/sysconfig/iptables-config
IPTABLES_MODULES=“nf_conntrack_ftp"
modproble  nf_conntrack_ftp
```

2.  放行请求报文： 命令连接：NEW, ESTABLISHED 数据连接：RELATED, ESTABLISHED 

```bash
iptables –I INPUT -d LocalIP -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A INPUT -d LocalIP -p tcp --dport 21 -m state --state NEW -j ACCEPT
```

3.  放行响应报文 

```bash
iptables -I OUTPUT -s LocalIP -p tcp -m state --state ESTABLISHED -j ACCEPT
```

具体操作： 

```bash
yum install vsftpd
systemctl start vsftpd
modprobe nf_conntrack_ftp
iptables -F
iptables -A INPUT   -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A INPUT -p tcp --dport 21 -m state --state NEW -j ACCEPT
iptables -A OUTPUT  -m state --state ESTABLISHED -j ACCEPT
iptables -P INPUT DROP
iptables -P OUTPUT DROP
iptables -vnL
```

##  iptables 规则保存

使用 iptables 命令定义的规则，手动删除之前，其生效期限为 kernel 存活期限

**持久保存规则** 

- CentOS 7,8 `iptables-save > /PATH/TO/SOME_RULES_FILE`
- CentOS 6

```bash
# 将规则覆盖保存至/etc/sysconfig/iptables文件中
service  iptables  save
```

**加载规则** 

- CentOS 7 重新载入预存规则文件中规则： `iptables-restore < /PATH/FROM/SOME_RULES_FILE` -n, --noflush：不清除原有规则 -t, --test：仅分析生成规则集，但不提交

- CentOS 6 

  ```bash
  # 会自动从/etc/sysconfig/iptables 重新载入规则
  service  iptables  restart
  ```

**开机自动重载规则** 

- 用脚本保存各 iptables 命令；让此脚本开机后自动运行 /etc/rc.d/rc.local 文件中添加脚本路径 /PATH/TO/SOME_SCRIPT_FILE

- 用规则文件保存各规则，开机时自动载入此规则文件中的规则 在/etc/rc.d/rc.local 文件添加 `iptables-restore < /PATH/FROM/IPTABLES_RULES_FILE`

- 定义 Unit File, CentOS 7，8 可以安装 iptables-services 实现 iptables.service 

  ```bash
  yum install iptables-services
  iptables-save > /etc/sysconfig/iptables
  systemctl enable iptables.service
  ```

### SNAT 实现

 SNAT：基于 nat 表的 target，适用于固定的公网 IP 

 例:10.0.1.0/24 网段的主机访问外部网络时，IP 数据包源地址被替换为 172.18.1.6-172.18.1.6 中的某一个地址

````bash
iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j SNAT --to-source 172.18.1.6-172.18.1.9
````

 另一个 target 为`MASQUERADE`，适用于动态的公网 IP，如拨号网络 

```bash
iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j MASQUERADE
```



### DNAT 实现

 DNAT：nat 表的 target，适用于端口映射 

- 例如

```bash
iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 22 -j DNAT --to-destination 10.0.1.22
iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 80 -j DNAT --to-destination 10.0.1.22:8080
```

### 转发 REDIRECT

 REDIRECT，是 NAT 表的 target，通过改变目标 IP 和端口，将接受的包转发至同一个主机 的不同端口，可用于 PREROUTING OUTPUT 链 

 ```bash
iptables -t nat -A PREROUTING -d 172.16.100.10 -p tcp --dport 80 -j REDIRECT --to-ports 8080
 ```

# 四. Linux启动流程和内核管理

## 系统启动流程

### Centos6

```bash
1.加载BIOS的硬件信息，获取第一个启动设备 
2.读取第一个启动设备MBR的引导加载程序(grub)的启动信息 
3.加载核心操作系统的核心信息，核心开始解压缩，并尝试驱动所有的硬件设备 
4.核心执行init程序，并获取默认的运行信息 
5.init程序执行/etc/rc.d/rc.sysinit文件 
6.启动核心的外挂模块
7.init执行运行的各个批处理文件(scripts) 
8.init执行/etc/rc.d/rc.local
9.执行/bin/login程序，等待用户登录 
10.登录之后开始以Shell控制主机
```

 启动过程总结：`/sbin/init --> (/etc/inittab) --> 设置默认运行级别  --> 运行系统初始脚本、完成系统初始化 --> (关闭对应下需要关闭的服务)启动 需要启动服务 --> 设置登录终端` 

 或者：`POST --> Boot Sequence(BIOS) --> Boot Loader -->  Kernel(ramdisk) --> rootfs --> switchroot --> /sbin/init  -->(/etc/inittab, /etc/init/*.conf) --> 设定默认运行级别 -->  系统初始化脚本rc.sysinit --> 关闭或启动对应级别的服务 --> 启动终端` 

- 运行级别：为系统运行或维护等目的而设定0-6：7个级别 

```bash
0：关机 
1：单用户模式(root自动登录), single, 维护模式 
2：多用户模式，启动网络功能，但不会启动NFS；维护模式 
3：多用户模式，正常模式；文本界面 
4：预留级别；可同3级别 
5：多用户模式，正常模式；图形界面 
6：重启 

默认级别：3, 5 
切换级别：init # 
查看级别：
    runlevel
    who -r 
```

- /etc/rc.d/rc.sysinit: 系统初始化脚本,主要做以下事务

```bash
(1) 设置主机名 
(2) 设置欢迎信息 
(3) 激活udev和selinux  
(4) 挂载/etc/fstab文件中定义的文件系统 
(5) 检测根文件系统，并以读写方式重新挂载根文件系统 
(6) 设置系统时钟 
(7) 激活swap设备 
(8) 根据/etc/sysctl.conf文件设置内核参数 
(9) 激活lvm及software raid设备 
(10) 加载额外设备的驱动程序 
(11) 清理操作 
```

- grub配置文件：/boot/grub/grub.conf 

```
default=#: 设定默认启动的菜单项；落单项(title)编号从0开始 
timeout=#：指定菜单项等待选项选择的时长 
splashimage=(hd#,#)/PATH/XPM_FILE：菜单背景图片文件路径 
password [--md5] STRING: 启动菜单编辑认证 
hiddenmenu：隐藏菜单 
title TITLE：定义菜单项“标题”, 可出现多次 
root (hd#,#)：查找stage2及kernel文件所在设备分区；为grub的根 
kernel /PATH/TO/VMLINUZ_FILE [PARAMETERS]：启动的内核 
initrd /PATH/TO/INITRAMFS_FILE: 内核匹配的ramfs文件 
password [--md5|--encrypted ] STRING: 启动选定的内核或操作系统时进行认证 
```

### Centos7

 **CentOS 7 引导顺序**  

```bash
UEFi或BIOS初始化，运行POST开机自检 
选择启动设备 
引导装载程序, centos7是grub2 
加载程序的配置文件： 
    /etc/grub.d/   
    /etc/default/grub  
    /boot/grub2/grub.cfg 
加载initramfs驱动模块 
加载内核选项 
内核初始化，centos7使用systemd代替init  
执行initrd.target所有单元，包括挂载/etc/fstab 
从initramfs根文件系统切换到磁盘根目录 
systemd执行默认target配置，配置文件/etc/systemd/system/default.target 
systemd执行sysinit.target初始化系统及basic.target准备操作系统 
systemd启动multi-user.target下的本机与服务器服务 
systemd执行multi-user.target下的/etc/rc.d/rc.local 
Systemd执行multi-user.target下的getty.target及登录服务 
systemd执行graphical需要的服务 
```

- 手动在grub命令行接口启动系统 

```bash
grub> root (hd#,#) 
grub> kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICE  
grub> initrd /initramfs-VERSION-RELEASE.img 
grub> boot 
```

**grub 配置文件**

```bash
[root@lab-server2 ~]# ll /boot/grub2/grub.cfg 
-rw-r--r--. 1 root root 4465 Dec 31 08:43 /boot/grub2/grub.cfg
```

### 破解CentOS7的root口令方法一

```bash
1.启动时任意键暂停启动 
2.按e键进入编辑模式 
3.将光标移动linux16开始的行，添加内核参数rd.break 
4.按ctrl-x启动  
5.mount –o remount,rw  /sysroot 
6.chroot /sysroot 
7.passwd root 
8.touch /.autorelabel 
9.exit 
10.reboot 
```

### 破解CentOS7的root口令方法二

```bash
1.启动时任意键暂停启动 
2.按e键进入编辑模式 
3.将光标移动linux16开始的行，改为rw init=/sysroot/bin/sh 
4.按ctrl-x启动  
5.hchroot /sysroot 
6.passwd root 
7.touch /.autorelabel 
8.exit 
9.reboot 
```

### 修复GRUB2

```bash
GRUB“the Grand Unified Bootloader” 
    引导提示时可以使用命令行界面 
    可从文件系统引导 
主要配置文件 /boot/grub2/grub.cfg 
修复配置文件 
    grub2-mkconfig > /boot/grub2/grub.cfg 
修复grub 
    grub2-install /dev/sda  BIOS环境 
    grub2-install  UEFI环境 
调整默认启动内核 
    vim /etc/default/grub 
    GRUB_DEFAULT=0 
```



## 内核管理

**sysctl命令查看当前生效的内核参数**

- 默认配置文件：/etc/sysctl.conf 

-  (1) 设置某参数  `sysctl -w parameter=VALUE`

-  (2) 通过读取配置文件设置参数  `sysctl -p [/path/to/conf_file]`  

- (3) 查看所有生效参数  `sysctl -a`


#### 内核常用参数

| 参数                                                         | 对应文件                                | 备注                                                         |
| ------------------------------------------------------------ | --------------------------------------- | ------------------------------------------------------------ |
| net.core.somaxconn = 4096                                    | /proc/sys/net/core/somaxconn            | 选项默认值是128，这个参数用于调节系统同时发起的tcp连接数，在高并发请求中，默认的值可能会导致连接超时或重传，因此，需要结合并发请求数来调节此值 |
| vm.swappiness = 1                                            | /proc/sys/vm/swappiness                 | 这个参数定义了系统对swap的使用倾向，centos7默认值为30，值越大表示越倾向于使用swap。可以设为0，这样做并不会禁止对swap的使用，只是最大限度地降低了使用swap的可能性 |
| net.ipv4.ip_forward = 1                                      | /proc/sys/net/ipv4/ip_forward           | 开启路由转发功能                                             |
| net.ipv4.icmp_echo_ignore_all = 1                            | /proc/sys/net/ipv4/icmp_echo_ignore_all | 禁ping                                                       |
| vm.drop_caches                                               | /proc/sys/vm/drop_caches                | 用来控制是否清空文件缓存：默认是0；1-清空页缓存；2-清空inode和目录树缓存；3-清空所有缓存 |
| fs.file-max = 1020000                                        | /proc/sys/fs/file-max                   | 系统级别的可打开文件句柄数                                   |
| ulimit -n                                                    | /etc/security/limits.conf               | 限制经过PAM模块认证的用户打开的文件句柄数：* soft nofile 65535         * hard nofile 65535 |
| net.ipv4.tcp_syncookies = 1                                  | /proc/sys/net/ipv4/tcp_syncookies       | 开启SYN Cookies，当SYN等待队列溢出时，启用cookies来处理，可以防范少量的SYN攻击，默认为0，表示关闭 |
| net.ipv4.tcp_tw_reuse = 1                                    | /proc/sys/net/ipv4/tcp_tw_reuse         | 允许将TIME_WAIT sockets重新用于新的TCP连接，默认为0，表示关闭 |
| net.ipv4.tcp_tw_recycle = 1                                  | /proc/sys/net/ipv4/*                    | 允许将TIME_WAIT sockets快速回收以便利用，默认为0，表示关闭，需要同时开启 net.ipv4.tcp_timestamps 才能生效 |
| net.ipv4.tcp_timestamps = 1                                  | /proc/sys/net/ipv4/*                    | 默认为1                                                      |
| net.ipv4.tcp_fin_timeout = 30                                | /proc/sys/net/ipv4/*                    | 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。默认是60s |
| net.ipv4.ip_local_port_range = 1024 65500                    | /proc/sys/net/ipv4/*                    | 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65500 |
| net.ipv4.tcp_max_syn_backlog = 8192                          | /proc/sys/net/ipv4/*                    | 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 |
| net.ipv4.tcp_max_tw_buckets = 5000                           | /proc/sys/net/ipv4/*                    | 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。 |
| net.ipv4.ip_nonlocal_bind = 1                                | /proc/sys/net/ipv4/ip_nonlocal_bind     | 此参数表示是否允许服务绑定一个本机不存在的IP地址； 使用场景：有些服务需要依赖一个vip才能启动，但是此vip不在本机上，当vip飘移到本机上时才存在；但是服务又需要提前启动，例如haproxy,nginx等代理需要绑定vip时； 0：默认值，表示不允许服务绑定一个本机不存的地址 1：表示允许服务绑定一个本机不存在的地址 |
| vm.overcommit_memory = 1                                     |                                         | vm.overcommit_memory：表示系统允许内存的分配情况 0：默认值；     表示内核将检查是否有足够的可用内存供应用进程使用；     如果有足够的可用内存，内存申请允许；     否则，内存申请失败，并把错误返回给应用进程。 1：表示内核允许分配所有的物理内存，而不管当前的内存状态如何。redis要把此参数设为1； 2：     表示允许分配的内存为：物理内存*vm.overcommit_ratio+交换空间;      与参数vm.overcommit_ratio结合使用； |
| cat /proc/meminfo \| awk '{print $1,$2/1024 " Mb"}' \| grep "Commit" |                                         | 查看系统中可提交的内存和已经申请的内存：   CommitLimit：表示系统可分配的内存     Committed_AS：表示系统已经分配的内存 |
| kernel.msgmax                                                |                                         | 进程间的通信需要依靠内核来进行管理；是通过消息列队来传递消息； 以字节为单位，规定消息的单大值； 默认为65536，即64k； 此值不能超过kernel.msgmnb的值，msgmnb限定了消息队列的最大值； |
| kernel.msgmnb                                                |                                         | 以字节为单位，规定了一个消息队列的最大值； 默认值为：65536，即64k； |
| kernel.mni                                                   |                                         | 指定消息队列的最大个数；                                     |
| kernel.shmall                                                |                                         | 以**页**为单位，控制共享内存总量；Linux一个内存页大小为4kb； |
| kernel.shmmax                                                |                                         | 定义单个共享内存段的最大值;  shmmax 设置应该足够大，设置的过低可能会导致需要创建多个共享内存段； |
| kernel.shmmni                                                |                                         | 定义共享内存段的个数，默认为4096；                           |
| net.ipv4.tcp_rmem = 4096/87380/67108864  net.ipv4.tcp_wmem = 4096/65536/67108864 |                                         | 增加tcp缓冲区大小，tcp_rmem表示接受数据缓冲区范围，tcp_wmem表示发送数据缓冲区范围，单位Byte，最大64M |
| net.ipv4.tcp_retries2 = 5                                    |                                         | TCP失败重传次数,默认值15，意味着重传15次才彻底放弃，可减少到5，以尽早释放内核资源;在通讯过程中（已激活的sock），数据包发送失败后，内核要重试发送多少次后才决定放弃连接 |

### 内核编译

#### 1.前提：

```
(1) 准备好开发环境 
(2) 获取目标主机上硬件设备的相关信息 
(3) 获取目标主机系统功能的相关信息 
    例如:需要启用相应的文件系统 
(4) 获取内核源代码包 
     www.kernel.org 
```

#### 2.开发环境准备

```
包组 
    Development Tools 
目标主机硬件设备相关信息 
    CPU： 
    cat /proc/cpuinfo 
    x86info -a 
    lscpu 
PCI设备： 
    lspci 
        -v 
        -vv 
    lsusb 
        -v 
        -vv 
块设备 
    lsblk 
了解全部硬件设备信息 
    hal-device：CentOS 6 
```

#### 3.步骤

```
安装开发包组 
下载源码文件 
.config：准备文本配置文件 
make menuconfig：配置内核选项 
make [-j #]  或者用两步实现： make -j # bzImage ; make -j # modules 
make modules_install：安装模块 
make install ：安装内核相关文件 
    安装bzImage为 /boot/vmlinuz-VERSION-RELEASE 
    生成initramfs文件 
    编辑grub的配置文件 
```

#### 编译内核两大步

- 1.配置内核选项 

```
支持“更新”模式进行配置：make help 
(a) make config：基于命令行以遍历的方式配置内核中可配置的每个选项 
(b) make menuconfig：基于curses的文本窗口界面 
(c) make gconfig：基于GTK (GNOME）环境窗口界面 
(d) make xconfig：基于QT(KDE)环境的窗口界面 
支持“全新配置”模式进行配置 
(a) make defconfig：基于内核为目标平台提供的“默认”配置进行配置 
(b) make allyesconfig: 所有选项均回答为“yes“ 
(c) make allnoconfig: 所有选项均回答为“no“ 
```

- 2.编译 

```
全编译:make [-j #]  
编译内核的一部分功能： 
(a) 只编译某子目录中的相关代码 
    cd /usr/src/linux 
    make dir/ 
(b) 只编译一个特定的模块 
    cd /usr/src/linux 
    make dir/file.ko 
    示例：只为e1000编译驱动： 
        make drivers/net/ethernet/intel/e1000/e1000.ko
```

#### 卸载内核

```
删除/lib/modules/目录下不需要的内核库文件 
删除/usr/src/linux/目录下不需要的内核源码 
删除/boot目录下启动的内核和内核映像文件 
更改grub的配置文件，删除不需要的内核启动列表 
    centos7:vim /boot/grub2/grub.cfg 
           :/menuentry
    centos8:
          rm -f /boot/loader/entries/7e3e9120767340a8bd946a83d7c3b84d-$(uname -r)-80.el8.x86_64.conf
```



## systemd服务

 **Systemd**：系统启动和服务器守护进程管理器，负责在系统启动或运行时，激 活系统资源，服务器进程和其它进程  

` POST --> Boot Sequence --> Bootloader --> kernel + initramfs(initrd) --> rootfs --> /sbin/init  `

**centos6 --> centos7:**

```
启动：service name start ==> systemctl start name.service 
停止：service name stop ==> systemctl stop name.service 
重启：service name restart ==> systemctl restart name.service 
状态：service name status ==> systemctl status name.service 

禁止自动和手动启动： systemctl mask name.service
取消禁止： systemctl unmask name.service 

服务查看

    查看某服务当前激活与否的状态： systemctl is-active name.service
    查看所有已经激活的服务：      systemctl list-units --type|-t service
    查看所有服务：              systemctl list-units --type service --all|-a

    重新加载配置 systemctl reload sshd.service
    列出活动状态的所有服务单元 systemctl list-units --type=service
    列出所有服务单元 systemctl list-units --type=service --all
    查看服务单元的启用和禁用状态 systemctl list-unit-files --type=service
    列出失败的服务 systemctl --failed --type=service
    列出依赖的单元 systemctl list-dependencies sshd
    验证sshd服务是否开机启动 systemctl is-enabled sshd
    禁用network，使之不能自动启动,但手动可以 systemctl disable network
    启用network systemctl enable network
    禁用network，使之不能手动或自动启动 systemctl mask network
    启用network systemctl unmask network

```



**运行级别** 

```bash
0  ==> runlevel0.target, poweroff.target 
1  ==> runlevel1.target, rescue.target 
2  ==> runlevel2.target, multi-user.target 
3  ==> runlevel3.target, multi-user.target 
4  ==> runlevel4.target, multi-user.target 
5  ==> runlevel5.target, graphical.target 
6  ==> runlevel6.target, reboot.target 
```

 获取默认运行级别：  `systemctl get-default` 

**传统命令init，poweroff，halt，reboot都成为systemctl的软链接** 

```bash
关机:systemctl halt、systemctl poweroff 
重启:systemctl reboot 
挂起:systemctl suspend 
休眠:systemctl hibernate 
休眠并挂起:systemctl hybrid-sleep 
```

# 4.5 文件管理

## linux文件系统简述

 linux文件系统中的文件名称**区分大小写**，其中**以点(.)开头的文件为隐藏文件** 

 文件由两类数据组成：

- 元数据：metadata
-  数据：data  

## linux下的文件命令规则

- **文件名最长255个字节**
- 包括**路径**在内**文件名**称**最长4095个字节**
- 蓝色–>目录 绿色–>可执行文件 红色–>压缩文件 浅蓝色–>链接文件 灰色–>其他文件  (可以自定义)
- **除了斜杠和NUL**,所有字符都有效.但使用特殊字符的目录名和文件不推荐使用，有些字符需要用引号来引用它们
- 标准Linux文件系统（如ext4），**文件名称大小写敏感**
   例如：MAIL, Mail, mail, mAiL

## 文件系统结构细节

| 目录           | 功能                                                         |
| -------------- | ------------------------------------------------------------ |
| /boot          | 引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录 |
| /bin           | 所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序 |
| /sbin          | 管理类的基本命令；不能关联至独立分区，OS启动即会用到的程序   |
| /lib           | 启动时程序依赖的基本共享库文件以及内核模块文件(/lib/modules) |
| /lib64         | 专用于x86_64系统上的辅助共享库文件存放位置                   |
| /etc           | 配置文件目录                                                 |
| /home/USERNAME | 普通用户家目录                                               |
| /root          | 管理员的家目录                                               |
| /media         | 便携式移动设备挂载点                                         |
| /mnt           | 临时文件系统挂载点                                           |
| /dev           | 设备文件及特殊文件存储位置                                   |
|                | b: block device，块设备，随机访问                            |
|                | c: character device，字符设备，线性访问                      |
| /opt           | 第三方应用程序的安装位置                                     |
| /srv           | 系统上运行的服务用到的数据                                   |
| /tmp           | 临时文件存储位置                                             |
| /usr           | universal shared, read-only data 全局共享的只读文件存放地    |
|                | /usr/bin: 保证系统拥有完整功能而提供的应用程序               |
|                | /usr/sbin: centos7上访问/sbin实质是访问 /usr/sbin            |
|                | /usr/lib：32位使用                                           |
|                | /usr/lib64：只存在64位系统                                   |
|                | /usr/include: C程序的头文件(header files)                    |
|                | /usr/share：结构化独立的数据，例如doc, man等                 |
|                | /usr/local：第三方应用程序的安装位置：bin, sbin, lib, lib64, etc, share |
| /var           | variable data files 可变文件存放地点                         |
|                | /var/cache: 应用程序缓存数据目录                             |
|                | /var/lib: 应用程序状态信息数据                               |
|                | /var/local：专用于为/usr/local下的应用程序存储可变数据       |
|                | /var/lock: 锁文件                                            |
|                | /var/log: 日志目录及文件                                     |
|                | /var/opt: 专用于为/opt下的应用程序存储可变数据               |
|                | /var/run: 运行中的进程相关数据,通常用于存储进程pid文件       |
|                | /var/spool: 应用程序数据池                                   |
|                | /var/tmp: 保存系统两次重启之间产生的临时数据                 |
| /proc          | 用于输出内核与进程信息相关的虚拟文件系统                     |
| /sys           | 用于输出当前系统上硬件设备相关信息虚拟文件系统               |
| /selinux       | security enhanced Linux，selinux相关的安全策略等信息的存储位置 |

## 文件种类

| 符号 | 文件类型         |
| ---- | ---------------- |
| -    | 普通文件         |
| d    | 目录文件         |
| b    | 块设备           |
| c    | 字符设备         |
| l    | 符号链接文件     |
| p    | 管道文件pipe     |
| s    | 套接字文件socket |

## 各类文件存放地

| 文件类型   | 存放的文件夹                                                 |
| ---------- | ------------------------------------------------------------ |
| 二进制程序 | /bin, /sbin, /usr/bin, /usr/sbin, /usr/local/bin, /usr/local/sbin |
| 库文件     | /lib, /lib64, /usr/lib, /usr/lib64, /usr/local/lib, /usr/local/lib64 |
| 配置文件   | /etc, /etc/DIRECTORY, /usr/local/etc                         |
| 帮助文件   | /usr/share/man, /usr/share/doc, /usr/local/share/man, /usr/local/share/doc |

## 绝对路径和相对路径

**绝对路径**：表示从根开始完整的文件的位置路径，以正斜杠开始，可用于任何想指定一个文件名的时候

**相对路径**：名指定相对于当前工作目录或某目录的位置，不以斜线开始，可以作为一个简短的形式指定一个文件名
查看路径的基名：`basename   /path/to/somefile`
查看某路径的目录名：`dirname    /path/to/somefile`

## linux下的inode解释

几乎每个文件系统都会需要大量不同的数据结构来保证其底层对各种文件存储目的的支持;在linux系统中（ext3或者ext4或者xfs文件系统）就有一个很重要的数据结构叫**inode**(index node),一个inode包含某个文件或者某个目录的以下信息（也叫元数据）： 

| 信息项                                                       | 英文术语                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 文件类型（可执行文件，块文件，字符文件等）                   | File types ( executable, block special etc )                 |
| 文件权限（读，写，执行等）                                   | Permissions ( read, write etc )                              |
| 文件属主全局唯一标识符                                       | UID ( Owner )                                                |
| 文件属组全局唯一标识符                                       | GID ( Group )                                                |
| 文件大小                                                     | FileSize/bytes                                               |
| 时间戳：最后访问时间、最后修改时间、最后改变时间和inode号变化信息 | Time stamps including last access, last modification and last inode number change. |
| 文件链接数（硬链接和软链接）                                 | Number of links ( soft/hard )                                |
| 文件在磁盘的位置                                             | Location of ile on harddisk.                                 |
| 该文件所分配的磁盘块数量                                     |                                                              |
| 其他信息                                                     | Some other metadata about file.                              |

（Under ext2, each i-node contains 15 pointers. The first 12 of these pointers (num-bered 0 to 11 in Figure 14-2) point to the location in the file system of the first 12 blocksof the file. The next pointer is a pointer to a block of pointers that give the locations ofthe thirteenth and subsequent data blocks of the file.）

在ext2文件系统中，每个i-node包含有15和数据块指针。前12个数据块指针(0-11)指向分配给该文件的前12个数据块在磁盘的位置。接下来的指针则指向下一个数据块或者指向一个指针块。

**inode数据结构被存储在inode表中**：由于每个inode代表某个文件的所有属性信息，所以inode表就记录了整个文件系统上的所有文件的信息（元数据）

linux文件系统中每个目录下的文件被存储成目录项，每一项对应其inode号，通过inode号就可以访问到inode表的某一项，该项就记录了该文件的元数据。如下图：

![](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\20191224193127136.png)

## cp命令与inode

分配一个空闲的inode号，在inode表中生成新条目；在目录中创建一个目录项，将名称与inode编号关联;拷贝数据生成新的文件 

## rm命令和inode

链接数递减，从而释放的inode号可以被重用，把数据块放在空闲列表中，删除目录项数据实际上不会马上被删除，但当另一个文件使用数据块时将被覆盖 

## mv命令和inode

 如果mv命令的目标和源在相同的文件系统，作为mv 命令 ：

- 用新的文件名创建对应新的目录项
- 删除旧目录条目对应的旧的文件名
- 不影响inode表（除时间戳）或磁盘上的数据位置：没有数据被移动！ 

 如果目标和源在一个不同的文件系统， mv相当于cp和rm 

## 硬链接和软链接

### 硬链接

 创建硬链接会增加额外的记录项以引用文件，对应于同一文件系统上同一个物理文件
 每个目录引用相同的inode号，创建时链接数递增 

-  硬链接，以文件副本的形式存在。但不占用实际空间。
-  不允许给目录创建硬链接 
-  硬链接只有在同一个文件系统中才能创建 
-  删除其中一个硬链接文件并不影响其他有相同 inode 号的文件 

> 删除文件时：
>
> >  rm命令递减计数的链接
> >  文件要存在，至少有一个链接数
> >  当链接数为零时，该文件被删除
> >  硬链接不能跨越驱动器或分区

```bash
为文件创建硬链接语法:
~# ln filename [linkname ]
```
### 符号（或软）链接

一个符号链接的数据内容是另一个文件的路径：

-  一个符号链接的数据内容是它引用文件的名称
- 可以对目录创建软连接
-  软链接可以对一个不存在的文件名进行链接，硬链接必须要有源文件
-  可以跨分区创建
-  指向的是另一个文件的路径
- 其大小为指向的路径字符串的长度
- 不增加或减少目标文件inode的引用计数
-  语法：

```bash
~# ln -s filename [linkname]
```

 **不论是硬链接或软链接都不会将原本的档案复制一份，只会占用非常少量的磁碟空间** 



# 五. Linux网络协议与管理



 **ISO网络7层模型**：

- 物理层：其为启动、维护和关闭物理链路规定了：电器特性、机械特性、过程特性和功能特性 

- 数据链路层： 有时也称网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡 
- 网络层： 有时也称作互联网层，其主要负责处理分组在网络中的活动，例如分组的选路。在TCP/IP协议族中，网络层协议包括IP协议（网际协议），ICMP协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议） 
- 传输层： 运输层主要为两台主机上的应用程序提供端到端的通信。在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议） 
- 会话层
- 表示层
- 应用层： 应用层负责处理特定的应用程序细节 



## 数据链路层

**在TCP/IP协议族中，数据链路层主要有三个目的**：

- （1）为IP模块发送和接收IP数据报；
- （2）为ARP模块发送ARP请求和接收ARP应答；
- （3）为RARP发送RARP请求和接收RARP应答。



**环回接口**

 大多数的产品都支持环回接口（Loopback Interface），以允许运行在同一台主机上的客户程序和服务器程序通过TCP/IP进行通信。A类网络号127就是为环回接口预留的。根据惯例，大多数系统把IP地址127.0.0.1分配给这个接口，并命名为localhost。一个传给环回接口的IP数据报不能在任何网络上出现 



## 网络层/IP协议

**IP协议**

 IP是TCP/IP协议族中最为核心的协议。所有的TCP、UDP、ICMP及IGMP数据都以IP数据报格式传输。许多刚开始接触TCP/IP的人对IP提供不可靠、无连接的数据报传送服务感到 很奇怪。IP提供的是一种不可靠的服务。也就是说，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。而另一方面，TCP在不可靠的IP层上提供了 一个可靠的运输层。为了提供这种可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制 

-  **不可靠（unreliable）**的意思是它不能保证IP数据报能成功地到达目的地。IP仅提供最好的传输服务。如果发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息报给信源端。任何要求的可靠性必须由上层来提供（如TCP） 
-  **无连接（connectionless）**这个术语的意思是IP并不维护任何关于后续数据报的状态信息。每个数据报的处理是相互独立的。这也说明，IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B），每个数据报都是独立地进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达 

**IP数据报文格式**：

![](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\20191025085607291.png)

**ICMP协议**：

Internet控制报文协议，主要用于传递差错报文和其他信息。ICMP报文通常被IP层或者更高层协议(TCP/UDP)使用。某些ICMP报文用来将差错报文传给用户进程 



**IGMP协议**：

Internet组管理协议，用于支持主机和路由器进行多播。它让一个物理网络上的所有系统知道主机当前所在的多播组。多播路由器需要这些信息以便知道多播数据报应该向哪些接口转发。和ICMP一样，IGMP也被当作IP层的一部分。IGMP报文通过IP数据报进行传输。不像我们已经见到的其他协议，IGMP有固定的报文长度，没有可选数据。IGMP报文通过IP首部中协议字段值为2来指明



**最大传输单元MTU**

以太网和802.3对数据帧的长度都有一个限制，其最大值分别是1500和1492字节。链路层的这个特性称作MTU，最大传输单元。不同类型的网络大多数都有一个上限。如果I P层有一个数据报要传，而且数据的长度比链路层的MTU还大，那么IP层就需要进行分片（fragmentation），把数据报分成若干片，这样每一片都小于MTU



**路径MTU**

当在同一个网络上的两台主机互相进行通信时，该网络的MTU是非常重要的。但是如果两台主机之间的通信要通过多个网络，那么每个网络的链路层就可能有不同的MTU。重要的不是两台主机所在网络的MTU的值，重要的是两台通信主机路径中的最小MTU。它被称作路径MTU。两台主机之间的路径MTU不一定是个常数。它取决于当时所选择的路由。而选路不一定是对称的（从A到B的路由可能与从B到A的路由不同），因此路径MTU在两个方向上
 不一定是一致的 



## 传输层/TCP协议

### TCP协议

尽管TCP和UDP都使用相同的网络层（IP），TCP却向应用层提供与UDP完全不同的服务。TCP提供一种面向连接的、可靠的字节流服务 

 **面向连接**：

意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。这一过程与打电话很相似，先拨号振铃，等待对方摘机说“喂”，然后才说明是谁

**可靠性的保证**：

- 应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的数据报长度将保持不变。由TCP传递给IP的信息单位称为报文段或段（segment） 
-  当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。TCP协议使用了自适应的超时及重传策略 
-  TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段（希望发端超时并重发） 
-  既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层 。 既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据 

-  TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只
   允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲
   区溢出 

两个应用程序通过TCP连接交换8bit字节构成的字节流。TCP不在字节流中插入记录标识符。我们将这称为字节流服务（bytestreamservice）。如果一方的应用程序先传10字节，又传20字节，再传50字节，连接的另一方将无法了解发方每次发送了多少字节。收方可以分4次接收这80个字节，每次接收20字节。一端将字节流放到TCP连接上，同样的字节流将出现在TCP连接的另一端； 另外，TCP对字节流的内容不作任何解释。TCP不知道传输的数据字节流是二进制数据，还是ASCII字符、EBCDIC字符或者其他类型数据。对字节流的解释由TCP连接双方的应用层
解释 

```bash
这种对字节流的处理方式与Unix操作系统对文件的处理方式很相似。Unix的内核对一个应用读或写的内容不作任何解释，而是交给应用程序处理。对Unix的内核来说，它无法区分一个二进制文件与一个文本文件
```

 **TCP报文段被封装在一个IP数据报中** ：

![](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\2019102511005542.png)



-  每个TCP段都包含源端和目的端的端口号，用于寻找发端和收端应用进程。这两个值加上IP首部中的源端IP地址和目的端IP地址唯一确定一个TCP连接， 插口对（socket pair）(包含客户IP地址、客户端口号、服务器IP地址和服务器端口号的四元组)可唯一确定互联网络中每个TCP连接的双方 

-  序号用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节。如果将字节流看作在两个应用程序间的单向流动，则TCP用序号对每个字节进行计数。序号是32bit的无符号数，序号到达232－1后又从0开始 
-  TCP可以表述为一个没有选择确认或否认的滑动窗口协议（滑动窗口协议用于数据传输）。我们说TCP缺少选择确认是因为TCP首部中的确认序号表示发方已成功收到字节，但还不包含确认序号所指的字节。当前还无法对数据流中选定的部分进行确认 、
- 在TCP首部中有6个标志比特。它们中的多个可同时被设置为1。 
  - URG 紧急指针（urgentpointer）有效。
  - ACK 确认序号有效。
  - PSH 接收方应该尽快将这个报文段交给应用层。
  - RST 重建连接。
  - SYN 同步序号用来发起一个连接。
  - FIN 发端完成发送任务
-  TCP的流量控制由连接的每一端通过声明的窗口大小来提供。窗口大小为字节数，起始于确认序号字段指明的值，这个值是接收端正期望接收的字节。窗口大小是一个16bit字段，因而窗口大小最大为65535字节。新的窗口刻度选项允许这个值按比例变化以提供更大的窗口 
-  **检验和**：覆盖了整个的TCP报文段：TCP首部和TCP数据。这是一个强制性的字段，一定是由发端计算和存储，并由收端进行验证。TCP检验和的计算和UDP检验和的计算相似 
-  只有当URG标志置1时紧急指针才有效。紧急指针是一个正的偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号。TCP的紧急方式是发送端向另一端发送紧急数据的一种方式。 
-  TCP报文段中的数据部分是可选的。接建立和一个连接终止时，双方交换的报文段仅有TCP首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中，也会发送不带任何数据的报文段 

### 三次握手

 TCP是一个面向连接的协议。无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接 。

- 1)请求端（通常称为客户）发送一个SYN段指明客户打算连接的服务器的端口，以及初始序号（ISN，在这个例子中为1415531521）。这个SYN段为报文段1。

- 2)服务器发回包含服务器的初始序号的SYN报文段（报文段2）作为应答。同时，将确认序号设置为客户的ISN加1以对客户的SYN报文段进行确认。一个SYN将占用一个序号。

- 3)客户必须将确认序号设置为服务器的ISN加1以对服务器的SYN报文段进行确认（报文段3）。通过这三个报文后就建立连接了。这个过程也称为三次握手(three-way handshake)。

![](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\20191025110255379.png)

### 四次挥手

 建立一个连接需要三次握手，而终止一个连接要经过4次握手。这由TCP的半关闭（half-close）造成的。既然一个TCP连接是全双工（即数据在两个方向上能同时传递），因此每个方向必须 单独地进行关闭。这原则就是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向连接。当一端收到一个FIN，它必须通知应用层另一端已经终止了那个方向的数据传 送。发送FIN通常是应用层进行关闭的结果 。

 收到一个FIN只意味着在这一方向上没有数据流动。**一个TCP连接在收到一个FIN后仍能发送数据**。而这对利用半关闭的应用来说是可能的，尽管在实际应用中只有很少的TCP应用程序这样做。  首先进行关闭的一方（即发送第一个FIN）将执行主动关闭，而另一方（收到这个FIN）执行被动关闭。通常一方完成主动关闭而另一方完成被动关闭，但也可能双方都执行主动关闭 

当服务器收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样， 一个FIN将占用一个序号。同时TCP服务器还向应用程序（即丢弃服务器）传送一个文件结束符。 接着这个服务器程序就关闭它的连接，导致它的TCP端发送一个FIN（报文段6），客户必须发回 一个确认，并将确认序号设置为收到序号加1（报文段7）。 发送FIN将导致 应用程序关闭它们的连接，这些FIN的ACK是由TCP软件自动产生的。连接通常是由客户端发起的， 这样第一个SYN从客户传到服务器。每一端都能主动关闭这个连接（即首先发送FIN）。然而，一般 由客户端决定何时终止连接，因为客户进程通常由用户交互控制，用户会键入诸如“quit”一样的 命令来终止进程 

#### 2MSL等待状态

 TIME_WAIT状态也称为2MSL等待状态。每个具体TCP实现必须选择一个报文段最大生存时间MSL（Maximum Segment Lifetime）。它是任何报文段被丢弃前在网络内的最长时间。我们知道这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段 

```bash
RFC 793 [Postel 1981c] 指出MSL为2分钟。然而，实现中的常用值是30秒，1分钟，或2分钟。
```

在实际应用中，对IP数据报TTL的限制是基于跳数，而不是定时器。对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在TIME_WAIT状态停留的时间为2倍的MSL。这样可让TCP再次发送最后的ACK以防这个ACK丢失（另一端超时并重发最后的FIN）

这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用

### UDP协议

 UDP是一个简单的面向数据报的运输层协议：进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。这与面向流字符的协议不同，如TCP，应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。UDP数据报被封装成一份IP数据报的格式 

#### 分用

当目的主机收到一个以太网数据帧时，数据就开始从协议栈中由底向上升，同时去掉各层协议加上的报文首部。每层协议盒都要去检查报文首部中的协议标识，以确定接收数据的上层协议。这个过程称作分用(Demultiplexing) 

## 应用层/HTTP协议



### PDU

 Protocol Data Unit,协议数据单元是指对等层次之间传递的数据单位  

- 物理层的 PDU是数据位 bit 
- 数据链路层的 PDU是数据帧 frame 
- 网络层的PDU是数据包 packet 
- 传输层的 PDU是数据段 segment 
- 其他更高层次的PDU是消息 message 

## 传统的IP地址分类

- 具体的网络数、所容纳的主机数及私网地址等如下：

```bash
1.A类地址：
  0000 0000 - 0111 1111: 1-127 
  网络数：126, 127 
  每个网络中的主机数：2^24-2 
  默认子网掩码：255.0.0.0 
  私网地址：10.0.0.0 
2.B类地址：
  1000 0000 - 1011 1111：128-191 
  网络数：2^14
  每个网络中的主机数：2^16-2 
  默认子网掩码：255.255.0.0 
  私网地址：172.16.0.0-172.31.0.0 
3.C类地址：
  1100 0000 - 1101 1111: 192-223 
  网络数：2^21 
  每个网络中的主机数：2^8-2 
  默认子网掩码：255.255.255.0 
  私网地址：192.168.0.0-192.168.255.0 
4.D类地址：
  D类地址为组播地址
  1110 0000 - 1110 1111: 224-239 
```

- 特殊地址

```bash
0.0.0.0 
    0.0.0.0不是一个真正意义上的IP地址。它表示所有不清楚的主机和目的网络 
255.255.255.255 
    限制广播地址。对本机来说，这个地址指本网段内(同一广播域)的所有主机 
127.0.0.1～127.255.255.254 
    本机回环地址，主要用于测试。在传输介质上永远不应该出现目的地址为“127.0.0.1”的数据包 
224.0.0.0到239.255.255.255 
    组播地址，224.0.0.1特指所有主机，224.0.0.2特指所有路由器。224.0.0.5指OSPF路由器，地址多用于一些特定的程序以及多媒体程序 
169.254.x.x 
    如果Windows主机使用了DHCP自动分配IP地址，而又无法从DHCP服务器获取地 址，系统会为主机分配这样地址
```



## CIDR表示的网络地址

- CIDR全称为：无类域内路由选择（Classless Inter-Domain Routing）
- 描述IP和网段时，子网掩码一般和IP成对出现，例如：192.168.123.234 255.255.255.0
   但是这种表示方法比较长，另一种比较方便的表示方法就叫CIDR表示法。其直接将子网掩码为1的位数写在IP地址的后面。例如：192.168.123.234 255.255.255.0 可以改写为：192.168.123.234/24(24就是子网掩码全为1的位数)。



## 路由的概念

- 每个数据包要在不同网络中传输，都需要进行路由，每次路由时都根据路由表中的记录决定下一跳该给谁。
- 路由分为： 
  - 主机路由
  - 网段路由
  - 默认路由

## Linux网络管理命令及配置

![](https://img-blog.csdnimg.cn/20191025134727495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lvdU9vcHM=,size_16,color_FFFFFF,t_70)



![](https://img-blog.csdnimg.cn/20191025134807866.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lvdU9vcHM=,size_16,color_FFFFFF,t_70)

## 多网卡绑定

将多块网卡绑定同一IP地址对外提供服务，可以实现高可用或者负载均衡。直接给两块网卡设置同 一IP地址是不可以的。通过bonding，虚拟一块网卡对外提供连接，物理网卡的被修改为相同的MAC地址。

Bonding工作模式

| mode                                                         | explain                                                      |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Mode 0 (balance-rr)                                          | 轮询（Round-robin）策略，从头到尾顺序的在每 一个slave接口上面发送数据包。本模式提供负载均衡和容错的能力 |
| Mode 1 (active-backup)                                       | 活动-备份（主备）策略，只有一个slave被激活，当且仅当活动的slave接口失败时才会激活其他slave.为了避免交换机发生混乱此时绑定的MAC地址只有一个外部端口上可见 |
| Mode 3 (broadcast)                                           | 广播策略，在所有的slave接口上传送所有的报文,提供容错能力     |
| active-backup、balance-tlb 和 balance-alb  模式不需要交换机的任何特殊配置。其他绑定模式需要配置交换机以便整合链接。如：Cisco 交换机需要在模式 0、2 和 3 中使用  EtherChannel，但在模式4中需要LACP和EtherChannel |                                                              |

 **桥接：**把一台机器上的若干个网络接口“连接”起来。其结果是，其中一个网收到的报文会被复制给其他网口并发送出去。以使得网口之间的报文能够互相转发。网桥就是这样一个设备，它有若干个网口，并且这些网口是桥接起来的。与网桥相连的主机就能通过交换机的报文转发而互相通信。 



# 六. 进程管理和任务计划

## 内核功能

| 内核功能                     | 解释                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| 进程调度                     | 现在的计算机一般会有多个物理核心用来执行程序的指令。Linux系统是一个抢占式多任务(preemptive  multitasking)的操作系统,多任务就意味着多个进程可以同时驻留在内存中得到CPU的处理，抢占式就意味着是哪个进程使用CPU或者使用多久的规则由内核进程调度器决定而不是CPU自己决定处理哪个进程 |
| 内存管理                     | 目前内存已近越来越大，但是软件体积也同样在增长；计算机的物理内存仍然是比较稀缺的资源，这就需要内核合理的管理分配内存给系统的各个进程 |
| 提供文件系统功能             | 内核能够在磁盘上创建特定文件系统，以允许文件被创建，复制更新和删除等 |
| 创建和销毁进程               | 内核可以加载某个程序到内存，并为其分配其运行所需要的资源(CPU、内存、对文件的访问等)，在内存中运行的某个程序的实例就叫做进程。当程序被内核销毁或者自己运行结束后，内核还需要保证其使用的资源被释放以便于后续进程重用 |
| 访问设备                     | 连接到计算机上的设备(如：麦克风、显示器、键盘鼠标、磁盘和磁带、软盘等)是的计算机内部和计算机之间及计算机和外部世界可以进行信息交互，允许计算机进行输入、输出等操作。内核为每个上层应用程序提供了一个标准的接口来访问设备，同时仲裁多个进程对设备的访问 |
| 提供网络功能                 | 内核代替用户进程收发网络数据。                               |
| 提供系统调用应用程序编程接口 | 进程可以通过一个入口请求内核完成多种操作，该入口就是系统调用 |
| 提供虚拟个人电脑抽象功能     | 在linux系统，多个用户可以同时登陆系统并进行不同的操作，内核提供了一个抽象层来保证各个用户的操作和对设备的使用的隔离性 |

## 程序？进程？线程？

|      |                                                              |
| ---- | ------------------------------------------------------------ |
| 程序 | 一般程序以两种形式存在：源代码的形式和二进制可执行程序的形式。源代码是人类可以读的文本(包括一系列的使用列如C语言编写的语句)。程序要被CPU执行，必须编译链接为计算机可以识别的二进制机器码指令(windows内的.exe文件；linux下的.o文件等)；二者被认为是同义词，都代表程序。 |
| 进程 | 简单的说，一个进程就是一个正在执行的程序的实例。当一个程序被执行时，内核会将该程序的指令加载进内存，分配内存空间给程序变量并设置相应的数据结构来记录该进程的信息(Linux内核对该种数据结构的实现叫task list，保存有进程ID、退出状态、用户ID和组ID等)。因此，进程也可以描述为：运行的程序及其包括的数据和操作。 |
| 线程 | 在现代的UNIX实现版中，每个进程可以有多个线程运行。一个理解线程比较好的表述是：共享同一块内存空间和其他属性的轻量级进程的集合。每个线程都执行同一个代码块并共享相同的数据区域和堆。然而，每个线程都有自己的栈空间(包含本地变量和函数调用连接信息)。线程之间可以通过其共享的全局变量进行通讯，进程亦可以通过IPC和同步机制进行通讯。 |

## 用户模式和内核模式

 现代处理器架构一般都允许CPU在至少两个不同模式运行：用户模式(user mode)和内核模式 (kernel mode：内核模式有时候也被称为监管模式)，CPU自带的硬件指令允许在两个模式之间切换。 相应地，虚拟内存的某部分可被标记为用户空间(user space)或内核空间(kernel space)。当在 用户模式运行某进程时CPU只可以访问标记为用户控件的内存区域，尝试访问被标记为内核空间的内存 将会导致一个硬件异常(hardware exception)错误。 



## 进程的状态

|          |                                                              |
| -------- | ------------------------------------------------------------ |
| 创建状态 | 进程在创建时需要申请一个空白PCB(process control block进程控 制块)，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完 成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 |
| 就绪状态 | 进程已准备好，已分配到所需资源，只要分配到CPU就能够立即运行  |
| 执行状态 | 进程处于就绪状态被调度后，进程进入执行状态                   |
| 阻塞状态 | 正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行进程受到阻塞。在满足请求时进入就绪状态等待系统调用 |
| 终止状态 | 进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 |

##  状态之间转换的四种情况 

|            |                                                              |
| ---------- | ------------------------------------------------------------ |
| 运行to就绪 | 1，主要是进程占用CPU的时间过长，而系统分配给该进程占用CPU的时间是有限的；2，在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行时，该进程就被迫让出CPU，该进程便由执行状态转变为就绪状态 |
| 就绪to运行 | 运行的进程的时间片用完，调度就转到就绪队列中选择合适的进程分配CPU |
| 运行to阻塞 | 正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如发生了I/O请求 |
| 阻塞to就绪 | 进程所等待的事件已经发生，就进入就绪队列                     |

## Linux的进程状态

- linux进程类型： 守护进程: daemon,在系统引导过程中启动的进程，和终端无关进程 前台进程：跟终端相关，通过终端启动的进程 注意：两者可相互转化
- linux进程状态： 运行态：running 就绪态：ready 睡眠态： 可中断睡眠态：interruptable 不可中断睡眠态：uninterruptable 停止态：stopped,暂停于内存，但不会被调度，除非手动启动 僵死态：zombie，结束进程，父进程结束前，子进程不关闭

**Linux进程优先级**

- 系统优先级：数字越小，优先级越高
- 0-139：每个优先级有140个运行队列和过期队列
- 实时优先级: 99-0   值最大优先级最高
- nice值：-20到19，对应系统优先级100-139



## 什么是作业?

- 在Linux中的作业是指正在运行的还没有结束的命令或者任务。Linux是个支持多任务的操作系统， 其允许多个命令同时执行(多核CPU真正的同时执行；单核CPU并发执行)。每个正在进行的作业被唯 一的作业号所标识。
- 要查看和控制作业主要使用以下命令 
  - jobs  列出正在运行或者挂起的作业
  - fg    将作业转换为前台作业
  - bg    将作业转换为后台作业
  - stop  挂起作业(Ctrl + z)
  - kill  结束作业(Ctrl + c)

 Linux中某个命令或脚本默认运行时为前台进程，可以使用Ctrl + c结束其；如果发起该命令或者 脚本的终端被关闭，那么该进程也就结束；这不利于需要长时间做某事的作业运行，在运行某命令或则 脚本时可以在其后加上&符号来使其以后台作业的方式运行，这样即使使用Ctrl+c或者关闭终端也不会 导致作业被终止 

![](F:\M39-Slides-Edited-notes\md_notes\Interview_exam_soluton_collection\png\20191027190430520.png)



## Linux任务计划

### 未来某时间点执行一次的任务

- 使用at命令来定义未来某时间点执行一次的任务
- at命令所在包：at

### 未来周期性执行的任务

- 计划周期性执行的任务提交给crond，到指定时间会自动运行
- 系统cron任务：系统维护的周期性作业,位于： /etc/crontab文件内，一般只有root可以更改。
- 用户cron任务：使用crontab命令来创建用户各自的周期性任务
- 日志：/var/log/cron
- 使用crontab命令来定义周期性计划任务

```bash
[root@centos7 ~]#cat /etc/crontab
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
# For details see man 4 crontabs
# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed
```

- 例如：晚上9点10分以用户steve的身份运行echo命令

```bash
10 21 * * *  steve  /bin/echo “Hello there!!”
```

- 例子:每3小时echo和wall命令 

```bash
0 */3 * * * steve /bin/echo “Done something!”; wall “Done something again!”
```

### 用户计划任务 

* crontab命令定义    

* 每个用户都有专用的cron任务文件：/var/spool/cron/USERNAME   

*  crontab命令：

  ```bash
  crontab [-u user] [-l | -r | -e] [-i] 
  -l 列出所有任务  
  -e 编辑任务  
  -r 移除所有任务  
  -i 同-r一同使用，以交互式模式移除指定任务  
  -u user 仅root可运行，指定用户管理cron任务
  ```

### Linux系统性能监控和管理命令

| 命令    | 作用                                                         | 备注 |
| ------- | ------------------------------------------------------------ | ---- |
| pstree  | pstree命令以树状结构显示当前系统进程                         |      |
| ps      | ps是linux系统中查看进程的有力工具之一。man帮助指明其用于报告当前系统所有进程的一个快照 |      |
| nice    | 使用nice命令指定一个调度优先级来运行某程序                   |      |
| renice  | renice命令可以更改一个正在运行的进程的优先级                 |      |
| pgrep   | pgrep和pkill命令大部分选项相同，也就是大部分功能相同；但是pgrep一般用来基于进程名搜索某进程，<br/> pkill一般基于进程名来发送相关信号给某进程 |      |
| kill    | kill命令一般用来结束某进程，但是其还有其他功能，用于发送特定的信号给相关进程来控制某进程 |      |
| killall | killall命令单纯的基于进程名来结束某进程                      |      |
| top     | 监控系统进程                                                 |      |
| htop    | 其使用不同的颜色来标识不同的信息，甚至支持鼠标点击相应的选项；来自EPEL源 |      |
| free    | 查看内存空间使用情况                                         |      |
| vmstat  | 命令查看虚拟内存信息                                         |      |
| iostat  | 统计CPU和设备IO信息                                          |      |
| iftop   | 显示带宽使用情况                                             |      |
| pmap    | 显示某进程对应的内存映射                                     |      |
| dstat   | dstat命令用来统计系统资源(代替vmstat和iostat)                |      |
| iotop   | iotop命令用来监视磁盘I/O使用状况                             |      |
| nload   | nload命令查看网络实时吞吐量                                  |      |

- lsof：列出打开的文件

```bash
查看由登陆用户启动而非系统启动的进程 
  lsof /dev/pts/1 
指定进程号，可以查看该进程打开的文件 
  lsof -p 9527
查看指定程序打开的文件 
  lsof -c httpd 
查看指定用户打开的文件 
  lsof -u root | more
查看指定目录下被打开的文件 
  lsof +D /var/log/
  lsof +d /var/log/ 
参数+D为递归列出目录下被打开的文件，参数+d为列出目录下被打开的文件
```

- lsof示例

```bash
查看所有网络连接 
  lsof -i –n 
  lsof -i@127.0.0.1
  通过参数-i查看网络连接的情况，包括连接的ip、端口等以及一些服务的连接情况，例如：sshd等。也可以通过
指定ip查看该ip的网络连接情况 
查看端口连接情况 
  lsof -i :80 -n 
  通过参数-i:端口可以查看端口的占用情况，-i参数还有查看协议，ip的连接情况等
查看指定进程打开的网络连接 
  lsof -i –n -a -p 9527
  参数-i、-a、-p等，-i查看网络连接情况，-a查看存在的进程，-p指定进程 
查看指定状态的网络连接 
  lsof -n -P -i TCP -s TCP:ESTABLISHED
  -n:no host names, -P:no port names,-i TCP指定协议，-s指定协议状态通过多个参数可以
清晰的查看网络连接情况、协议连接情况等
恢复删除文件 
  lsof |grep /var/log/messages 
  rm -f /var/log/messages 
  lsof |grep /var/log/messages 
  cat /proc/653/fd/6 
况 
查看端口连接情况 
  lsof -i :80 -n 
  通过参数-i:端口可以查看端口的占用情况，-i参数还有查看协议，ip的连接情况等
查看指定进程打开的网络连接 
  lsof -i –n -a -p 9527
  参数-i、-a、-p等，-i查看网络连接情况，-a查看存在的进程，-p指定进程 
查看指定状态的网络连接 
  lsof -n -P -i TCP -s TCP:ESTABLISHED
  -n:no host names, -P:no port names,-i TCP指定协议，-s指定协议状态通过多个参数可以
清晰的查看网络连接情况、协议连接情况等
恢复删除文件 
  lsof |grep /var/log/messages 
  rm -f /var/log/messages 
  lsof |grep /var/log/messages 
  cat /proc/653/fd/6 
  cat /proc/653/fd/6 > /var/log/messages 
```



# 6.5 文本处理三剑客

## 基本文本处理练习

```bash
1、找出ifconfig “网卡名” 命令结果中本机的IPv4地址
    ifconfig | head -n2 | tail -n1 | tr -s " " | cut -d" " -f3 # centos7,8
    ifconfig | head -n2 | tail -n1 | tr -s " " | cut -d" " -f3 | cut -d: -f2 # centos6
    ifconfig | grep -Eo "([0-9]{,3}\.){3}[0-9]{,3}" | head -n1 # centos6,7,8
    ifconfig | grep -Eo '\<(([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\>' | head -n1   # 精确

2、查出分区空间使用率的最大百分比值
    df -h | grep -e /dev/sd -e /dev/nvme | tr -s " " | cut -d" " -f5 | sort -nr  | head -n3

3、查出用户UID最大值的用户名、UID及shell类型
    getent passwd | sort -t : -k 3 -nr | head -n1 | cut -d: -f1,3,7
    getent passwd | sort -t : -k 3 -nr | cut -d: -f1,3,7 | head -n1

4、查出/tmp的权限，以数字方式显示
    stat /tmp/ | head -n4 | tail -n1 | cut -d \( -f2 | cut -d/ -f1
    stat /tmp/ | grep -E "(\([0-7]{4})" | grep -Eo [0-9]{4} |head -n1

5、统计当前连接本机的每个远程主机IP的连接数，并按从大到小排序
    ss -tun |grep ESTAB | tr -s " " | cut -d" " -f6 | cut -d: -f1 | sort | uniq -c | sort -nr
    tr -s " " ":" < ss.log | cut -d: -f6 | sort | uniq -c| sort -nr
    ss -tun |grep ESTAB | tr -s " " ":" | cut -d: -f7 | sort | uniq -c | sort -nr
```

## 通配符练习

```bash
1、显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录
    ls -d /var/l*[0-9]*[[:lower:]]
2、显示/etc目录下以任意一位数字开头，且以非数字结尾的文件或目录
    ls -d /etc/[[:digit:]]*[^[:digit:]]
3、显示/etc/目录下以非字母开头，后面跟了一个字母及其它任意长度任意字符的文件或目录
    ls -d /etc/[^[:alpha:]][[:alpha:]]*
4、显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其它为任意字符的文件或目录
    ls -d /etc/rc[0-6]*
5、显示/etc目录下，所有以.d结尾的文件或目录
    ls /etc/*.d -d
6、显示/etc目录下，所有.conf结尾，且以m,n,r,p开头的文件或目录
    ls /etc/[mnpr]*.conf -d
7、只显示/root下的隐藏文件和目录
    ls -d /root/.* (ls -d .[^.]*)
8、只显示/etc下的非隐藏目录
    ls /etc/*/ -d
```

## grep

### grep选项

```bash
"PATTERN" 为基本正则表达式
grep [OPTIONS] PATTERN [FILE...]
grep [OPTIONS] -e PATTERN ... [FILE...]
grep [OPTIONS] -f FILE ... [FILE...]
    -E   # 使用扩展正则表达式
    -o   # 只显示匹配到的字符串而不显示其所在的行的内容
    -v   # 显示未匹配到的行
    -i   # 忽略大小写
    -q   # 静默模式，无论是否匹配到都不打印标准输出
    -f file,--file=FILE # 从文件file中读取正则表达式
    -e # 使用多个操作来匹配模式
        grep -e root -e bash /etc/passwd # 匹配包含root和bash的行
    -w # 匹配单词
    -c, --count # 匹配到的行计算总数
    -s, --no-messages # 对不存在或则不可读文件的错误不打印
    -n, --line-number # 对匹配到的行加行号
    -A NUM, --after-context=NUM # 匹配到某模式时不仅打印匹配到的行还打印其后的NUM行
    -B NUM, --before-context=NUM # 匹配到某模式时不仅打印匹配到的行还打印其前的NUM行 
    -C NUM, -NUM, --context=NUM # 匹配到某模式时不仅打印匹配到的行还打印其前和其后的的NUM行 
    --color=auto # 对匹配到的文本着色显示 
    -m  #  匹配#次后停止 
```

 **正则表达式(REGEXP:Regular Expressions)**是由一类特殊字符及文本字符所编写的模式,其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能 

 **正则表达式引擎**：采用不同算法，检查处理正则表达式的软件模块 如：PCRE（Perl Compatible Regular Expressions） 

####  正则表达式元字符分类：

##### 字符匹配

```bash
.         匹配任意单个字符 
[]        匹配指定范围内的任意单个字符，示例：[wang]   [0-9]    [a-z]   [a-zA-Z] 
[^]       匹配指定范围外的任意单个字符 
[:alnum:] 字母和数字  
[:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z 
[:lower:] 小写字母    [:upper:] 大写字母 
[:blank:] 空白字符（空格和制表符） 
[:space:] 水平和垂直的空白字符（比[:blank:]包含的范围广） 
[:cntrl:] 不可打印的控制字符（退格、删除、警铃...） 
[:digit:] 十进制数字 [:xdigit:]十六进制数字 
[:graph:] 可打印的非空白字符 
[:print:] 可打印字符 
[:punct:] 标点符号
```

##### 匹配次数

 用在要指定次数的字符后面，用于指定前面的字符要出现的次数 

```bash
*  匹配前面的字符任意次，包括0次 
   贪婪模式：尽可能长的匹配 
.* 任意长度的任意字符 
\? 匹配其前面的字符0或1次 
\+ 匹配其前面的字符至少1次 
\{n\} 匹配前面的字符n次 
\{m,n\} 匹配前面的字符至少m次，至多n次 
\{,n\} 匹配前面的字符至多n次 
\{n,\} 匹配前面的字符至少n次 
```



##### 位置锚定

```py
^ 行首锚定，用于模式的最左侧 
$ 行尾锚定，用于模式的最右侧 
^PATTERN$  用于模式匹配整行 
^$  空行 
^[[:space:]]*$  空白行 
\< 或 \b 词首锚定，用于单词模式的左侧 
\> 或 \b 词尾锚定，用于单词模式的右侧 
\<PATTERN\> 匹配整个单词 
```

##### 分组

 分组：() 将一个或多个字符捆绑在一起，当作一个整体处理如：(root)+ 

#####  后向引用

引用前面的分组括号中的模式所匹配字符，而非模式本身; 分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些 变量的命名方式为: \1, \2, \3, … ;

\1  表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符 

```bash
示例：  \(string1\(string2\)\)

      \1 ：string1\(string2\) 

      \2 ：string2 
或者：\|
a\|b
     a或b
C\|cat
    C或cat
\(C\|c\)at
    Cat或cat
```

##### 基本正则表达式练习

```bash
 grep "^[sS].*" /proc/meminfo
    grep "^[s]\|^[S].*" /proc/meminfo
    grep "^s\|^S.*" /proc/meminfo

2、显示/etc/passwd文件中不以/bin/bash结尾的行
    grep -v "\<bin/bash\>$" /etc/passwd
    grep -v "\bbin/bash\b$" /etc/passwd

3、显示用户rpc默认的shell程序 
    getent passwd | grep -w "rpc" | cut -d: -f1,7
    grep -w "rpc" /etc/passwd | cut -d: -f1,7

4、找出/etc/passwd中的两位或三位数
    grep --color=auto -o "[0-9]\{2,3\}" /etc/passwd

5、显示CentOS7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面有非
空白字符的行
    grep "^[[:space:]].*" /etc/grub2.cfg
    grep "^ .*" /etc/grub2.cfg

6、找出“netstat -tan”命令结果中以LISTEN后跟任意多个空白字符结尾的行
    netstat -tan | grep "LISTEN \+"

7、显示CentOS7上所有UID小于1000以内的用户名和UID
    grep --color=auto -v ".*[0-9]\{4\}.*" /etc/passwd | cut -d: -f1,3

8、添加用户bash、testbash、basher、sh、nologin(其shell为/sbin/nologin),找
出/etc/passwd用户名和shell同名的行
    grep "^\(\<.*\>\).*/\1$" /etc/passwd

9、利用df和grep，取出磁盘各分区利用率，并从大到小排序 
    df -h | grep -o "\<[0-9]\{,3\}%" | sort -nr
    df -h | grep -o "\<[0-9]\{,3\}%" | sort -nr | cut -d% -f1
```

##### 扩展正则表达式练习

```bash
1、显示三个用户root、mage、wang的uid和默认shell
    getent passwd | grep -w -e ^root -e ^mage -e ^wang | cut -d: -f3,7

2、找出/etc/rc.d/init.d/functions文件中行首为某单词(包括下划线)后面跟一
   个小括号的行
    grep "^\(.*\)_\?\(.*\)()"  /etc/rc.d/init.d/functions

3、使用egrep取出/etc/rc.d/init.d/functions中其基名
    echo /etc/rc.d/init.d/functions|egrep -o "[^/]+/?$"

4、使用egrep取出上面路径的目录名
    echo /etc/rc.d/init.d/functions/ |egrep -o "/.*[^/]"|egrep -o "/.*/"

5、统计last命令中以root登录的每个主机ip地址登录次数 
    last | grep root | egrep "\b(([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\b" | tr -s " " | cut -d" " -f3 | uniq -c | sort -nr

6、利用扩展正则表达式分别表示0-9、10-99、100-199、200-249、250-255
    [0-9] 
    [1-9][0-9] 
    1[0-9]{2}
    2[0-4][0-9]
    25[0-5]

7、显示ifconfig命令结果中所有ipv4地址 
    ifconfig | egrep "\b(([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\b"

8、将此字符串：welcome to  magedu linux 中的每个字符去重并排序，重复次数多的排到前面 
    echo "welcome to  magedu linux" | grep -o . | sort | uniq -c | sort -nr 
```



## SED

```bash
sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。
```

### 基本选项功能和用法

```bash
sed [option]... 'script' inputfile...
    -n  不输出模式空间内容到屏幕，即不自动打印
    -e  多点编辑
    -f   /PATH/SCRIPT_FILE 从指定文件中读取编辑脚本
    -r  支持使用扩展正则表达式
    -i.bak  备份文件并原处编辑
    script: '地址命令'
    注意：sed的脚本、地址定界和命令都一般写在单引号中间
```

- 地址定界

```bash
(1) 不给地址：对全文进行处理
(2) 单地址：
    #：指定的行
    $：最后一行
    /pattern/：被此处模式所能够匹配到的每一行
(3) 地址范围：
    #,#
    #,+#
    /pat1/,/pat2/ #模式1到模式2之间的行
    #,/pat1/
(4) ~：步进
    1~2 奇数行
    2~2 偶数行
```

- 编辑命令

```bash
    d   删除模式空间匹配的行，并立即启用下一轮循环
    p   打印当前模式空间内容，追加到默认输出之后
    a   [\]text 在指定行后面追加文本，支持使用\n实现多行追加
    i   [\]text 在行前面插入文本
    c   [\]text 替换行为单行或多行文本
    w   /path/file 保存模式匹配的行至指定文件
    r   /path/file 读取指定文件的文本至模式空间中匹配到的行后
    =   为模式空间中的行打印行号
    !   模式空间中匹配行取反处理
```

```bash
s///  
查找替换,支持使用其它分隔符，s@@@，s###
替换标记：
    g 行内全局替换
    p 显示替换成功的行
    w   /PATH/FILE 将替换成功的行保存至文件中
```

#### 示例

```bash
 	sed ‘2p’  /etc/passwd
    sed  -n ‘2p’ /etc/passwd
    sed  -n ‘1,4p’ /etc/passwd
    sed  -n ‘/root/p’  /etc/passwd
    sed  -n ‘2,/root/p’  /etc/passwd 从2行开始
    sed  -n ‘/^$/=’  file 显示空行行号
    sed  -n  -e ‘/^$/p’ -e ‘/^$/=’  file
    Sed '/root/a\superman'  /etc/passwd 在匹配到的行后追加superman
    sed '/root/i\superman' /etc/passwd 在匹配到的行前追加superman
    sed '/root/c\superman' /etc/passwd 匹配到的行替换为superman

    sed ‘1,10d’  file
    nl   /etc/passwd | sed ‘2,5d’
    nl   /etc/passwd | sed ‘2a tea’
    sed 's/test/mytest/g' example
    sed –n ‘s/root/&superman/p’ /etc/passwd 在root单词后追加superman
    sed –n ‘s/root/superman&/p’ /etc/passwd 在root单词前追加superman
    sed -e ‘s/dog/cat/’ -e ‘s/hi/lo/’ pets
    sed –i.bak  ‘s/dog/cat/g’ pets
```

#### 练习

```bash
1、删除centos7系统/etc/grub2.cfg文件中所有以空白开头的行行首的空白字符
    sed -inr 's#^ +(.*)#\1#p' /etc/grub2.cfg

2、删除/etc/fstab文件中所有以#开头，后面至少跟一个空白字符的行的行首的#和空白字符
    sed -inr 's#^# +(.*)#\1#p' /etc/grub2.cfg

3、在centos6系统/root/install.log每一行行首增加#号
    sed -inr 's#.*#\#&#p' /etc/grub2.cfg

4、在/etc/fstab文件中不以#开头的行的行首增加#号
    sed -inr 's#^[^#](.*)#\#\1#p' /etc/grub2.cfg

5、处理/etc/fstab路径,使用sed命令取出其目录名和基名
    echo /etc/fstab/ | sed -nr 's#(.*/)([^/]+)/?#\1#p'
    echo /etc/fstab/ | sed -nr 's#(.*/)([^/]+)/?#\2#p'

6、利用sed 取出ifconfig命令中本机的IPv4地址
    ifconfig eth0|sed -nr '2s@[^0-9]+([.0-9]+).*@\1@p'

7、统计centos安装光盘中Package目录下的所有rpm文件的以.分隔倒数第二个字段的重复次数
    ls /misc/cd/{BaseOS,AppStream}/Packages/ | sed -nr 's#.*\.(.*)\.rpm#\1#p' | sort |uniq -c | sort -nr
    ls /misc/cd/{BaseOS,AppStream}/Packages/ | rev | cut -d. -f2 | sort | uniq -c | uniq

8、统计/etc/init.d/functions文件中每个单词的出现次数，并排序（用grep和sed两种方法分别实现）
    grep -Eow "[^[:punct:]]+([[:alpha:]0-9+])" /etc/init.d/functions | grep -Eow "[[:alpha:]]+|[0-9]+" | wc -l
    sed -r "s/[^[:alpha:]]/\n/g" /etc/init.d/functions| sort | uniq -c | sort -nr

9、将文本文件的n和n+1行合并为一行，n为奇数行
    seq 10 | sed -nr '1~2N;s/\n/ /p' 
```



## AWK

### 基本用法

```bash
awk [options]  'program'  var=value   file… 
awk [options]  -f programfile    var=value  file… 
awk [options]  'BEGIN{action;… }pattern{action;… }END{action;… }'  file ... 
```

### 工作原理

```py
第一步：执行BEGIN{action;… }语句块中的语句 
第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ action;… }语句块，
它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。
第三步：当读至输入流末尾时，执行END{action;…}语句块 
BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，
比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中 
END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的
分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块
pattern语句块中的通用命令是最重要的部分，也是可选的。如果没有提供
pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每
一行都会执行该语句块 
```

### print格式

print item1, item2, …

```
(1) 逗号分隔符 
(2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式 
(3) 如省略item，相当于print $0 
```

- 示例：

```bash
awk  '{print "hello,awk"}' 
awk –F:   '{print}'   /etc/passwd 
awk –F: '{print "wang"}'   /etc/passwd 
awk –F:  '{print $1}'  /etc/passwd 
awk –F:  '{print $0}'  /etc/passwd 
awk –F:  '{print $1"\t"$3}'  /etc/passwd 
grep “ÛUID”/etc/fstab  |  awk '{print $2,$4}' 
```

### awk变量

 可以使用内置变量也可以自定义变量 

```bash
FS:Field Separator
    输入字段分隔符，默认为空白字符 
    awk -v FS=':'  '{print $1,FS,$3}' /etc/passwd 
    awk  –F:   '{print $1,$3,$7}'   /etc/passwd 
OFS:Output Field Separator
    输出字段分隔符，默认为空白字符 
    awk  -v FS=':'  -v OFS=':'  '{print $1,$3,$7}'   /etc/passwd 
RS:Record Seperator
    输入记录分隔符，指定输入时的换行符 
    awk -v RS=' ' ‘{print }’ /etc/passwd 
ORS:Output Record Seperator
    输出记录分隔符，输出时用指定符号代替换行符 
    awk -v RS=' ' -v ORS='###'  '{print $0}' /etc/passwd 
NF:Number Field
    字段数量 
    awk  -F：'{print NF}'  /etc/fstab 引用变量时，变量前不需加$ 
    awk  -F：'{print $(NF-1)}'  /etc/passwd 
NR:Number Record
    记录号 
    awk '{print NR}'  /etc/fstab ; awk END '{print NR}'  /etc/fstab 
FNR：各文件分别计数,记录号 
    awk '{print FNR}'  /etc/fstab /etc/inittab 
FILENAME：当前文件名 
    awk '{print FILENAME}'  /etc/fstab 
ARGC：命令行参数的个数 
    awk '{print ARGC}'  /etc/fstab /etc/inittab 
    awk 'BEGIN {print ARGC}'  /etc/fstab /etc/inittab 
ARGV：数组，保存的是命令行所给定的各参数 
    awk 'BEGIN {print ARGV[0]}'  /etc/fstab /etc/inittab 
    awk 'BEGIN {print ARGV[1]}'  /etc/fstab /etc/inittab 
```

- 自定义变量(区分字符大小写)

```bash
(1) -v var=value 
(2) 在program中直接定义 
```

- 示例：

```bash
awk  -v test='hello gawk' '{print test}' /etc/fstab  
awk  -v test='hello gawk' 'BEGIN{print test}'  
awk  'BEGIN{test="hello,gawk";print test}'  
awk  -F: '{sex=“male”;print $1,sex,age;age=18}' /etc/passwd 

cat awkscript 
{print script,$1,$2} 
awk  -F: -f awkscript script="awk" /etc/passwd 
```

### awk 格式化-printf

 格式化输出：`printf "FORMAT", item1, item2, ...` 

```bash
(1) 必须指定FORMAT 
(2) 不会自动换行，需要显式给出换行控制符，\n 
(3) FORMAT中需要分别为后面每个item指定格式符 
```

 格式符：与item一一对应 

```bash
%c：显示字符的ASCII码 
%d, %i：显示十进制整数 
%e, %E：显示科学计数法数值 
%f：显示为浮点数 
%g, %G：以科学计数法或浮点形式显示数值 
%s：显示字符串 
%u：无符号整数 
%%：显示%自身
```

 修饰符 

```bash
#[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f 
- 左对齐（默认右对齐） %-15s 
+ 显示数值的正负符号 %+d
```

#### printf示例

```bash
awk -F:   '{printf "%s",$1}' /etc/passwd 
awk -F:   '{printf "%s\n",$1}' /etc/passwd 
awk -F:   '{printf "%-20s %10d\n",$1,$3}' /etc/passwd 
awk -F:   '{printf "Username: %s\n",$1}'  /etc/passwd 
awk -F:   '{printf “Username: %s,UID:%d\n",$1,$3}' /etc/passwd 
awk -F:   '{printf "Username: %15s,UID:%d\n",$1,$3}' /etc/passwd 
awk -F:   '{printf "Username: %-15s,UID:%d\n",$1,$3}'  /etc/passwd 
```

#### awk示例

```bash
awk  -F: '$0 ~ /root/{print $1}'  /etc/passwd 
awk  '$0~“^root"'     /etc/passwd  
awk  '$0  !~ /root/'   /etc/passwd 
awk  -F: '$3==0'     /etc/passwd 

awk -F:   '$3>=0 && $3<=1000 {print $1}'  /etc/passwd 
awk -F:   '$3==0 || $3>=1000 {print $1}'  /etc/passwd  
awk -F:   '!($3==0) {print $1}'     /etc/passwd 
awk -F:   '!($3>=500) {print $3}' /etc/passwd 
awk   '/ÛUID/{print $1}'     /etc/fstab 
awk   '!/ÛUID/{print $1}'   /etc/fstab 

awk   -F:  'i=1;j=1{print i,j}' /etc/passwd 
awk  '!0'  /etc/passwd ;  
awk  '!1'   /etc/passwd 
awk  -F: '$3>=1000{print $1,$3}'  /etc/passwd 
awk  -F: '$3<1000{print $1,$3}'  /etc/passwd 
awk  -F: '$NF=="/bin/bash"{print $1,$NF}' /etc/passwd 
awk  -F: '$NF ~ /bash$/{print $1,$NF}' /etc/passwd 

awk -F : 'BEGIN {print "USER USERID"} {print $1":"$3}END{print "END FILE"}' /etc/passwd 
awk -F: '{print "USER USERID";print $1":"$3} END{print "END FILE"}'  /etc/passwd 
awk -F: 'BEGIN{print "USER  UID  \n--------------- "}{print $1,$3}'  /etc/passwd 
awk -F: 'BEGIN{print "USER UID  \n--------------- "}{print $1,$3}END{print "=============="}' /etc/passwd 
seq 10 | awk     'i=0' 
seq 10 | awk     'i=1' 
seq 10 | awk     'i=!i' 
seq 10 | awk     '{i=!i;print i}' 
seq 10 | awk   ‘!(i=!i)'               
seq 10 | awk       -v  i=1 'i=!i' 
```

#### awk if

 语法：`if(condition1){statement1}else if(condition2){statement2}else{statement3}` 

```bash
awk -F: '{if($3>=1000)print $1,$3}' /etc/passwd 
awk -F: '{if($NF=="/bin/bash") print $1}' /etc/passwd 
awk '{if(NF>5) print $0}' /etc/fstab 
awk -F: '{if($3>=1000) {printf "Common user: %s\n",$1} else {printf "root or Sysuser: %s\n",$1}}' /etc/passwd 
awk -F: '{if($3>=1000) printf "Common user: %s\n",$1; else printf "root or Sysuser: %s\n",$1}' /etc/passwd 
df -h|awk -F% '/^\/dev/{print $1}'|awk '$NF>=80{print $1,$5}' 
awk 'BEGIN{ test=100;if(test>90){print "very good"} 
else if(test>60){ print "good"}else{print "no pass"}}' 
```

#### awk while

```bash
awk '/^[[:space:]]*linux16/{i=1;while(i<=NF)  
{print $i,length($i); i++}}' /etc/grub2.cfg 
awk  '/^[[:space:]]*linux16/{i=1;while(i<=NF)  
{if(length($i)>=10){print $i,length($i)}; i++}}' /etc/grub2.cfg 
```

#### do while

```bash
awk 'BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i<=100);print i}'
```

#### awk for

```bash
awk '/^[[:space:]]*linux16/{for(i=1;i<=NF;i++) {print $i,length($i)}}' /etc/grub2.cfg
```

#### awk 数组

```bash
weekdays["mon"]="Monday"  
awk 'BEGIN{weekdays["mon"]="Monday";weekdays["tue"]="Tuesday"; 
print weekdays["mon"]}‘ 
awk '!line[$0]++'  dupfile 
awk '{!line[$0]++;print $0, line[$0]}'  dupfile 

awk 'BEGIN{weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";for(i in weekdays) {print weekdays[i]}}' 
netstat -tan | awk '/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}' 
awk  '{ip[$1]++}END{for(i in ip) {print i,ip[i]}}'   /var/log/httpd/access_log 
```

#### awk函数

- rand()：返回0和1之间一个随机数
  `awk 'BEGIN{srand(); for (i=1;i<=10;i++)print int(rand()*100) }'`
- length([s])：返回指定字符串的长度
- sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s
  `echo "2008:08:08 08:08:08" | awk 'sub(/:/,"-",$1)'`
  `echo "2008:08:08 08:08:08" | awk '{sub(/:/,"-",$1);print $0}'`
- gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容
  `echo "2008:08:08 08:08:08" | awk 'gsub(/:/,"-",$0)'`
  `echo "2008:08:08 08:08:08" | awk '{gsub(/:/,"-",$0);print $0}'`
- split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array
  所表示的数组中，第一个索引值为1,第二个索引值为2,…
  `netstat -tn | awk '/^tcp\>/{split($5,ip,":");count[ip[1]]++}END{for (i in count) {print i,count[i]}}'`

#### awk使用system命令调用shell命令

# 七. MySQL

## MySQL存储引擎

###  MySQL支持哪些存储引擎?

`SHOW ENGINES\G;`查看支持的存储引擎

```bash
MariaDB [(none)]> show engines;
+--------------------+---------+----------------------------------------------------------------------------------+--------------+------+------------+
| Engine             | Support | Comment                                                                          | Transactions | XA   | Savepoints |
+--------------------+---------+----------------------------------------------------------------------------------+--------------+------+------------+
| InnoDB             | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys       | YES          | YES  | YES        |
| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                                            | NO           | NO   | NO         |
| MyISAM             | YES     | Non-transactional engine with good performance and small data footprint          | NO           | NO   | NO         |
| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears)                   | NO           | NO   | NO         |
| PERFORMANCE_SCHEMA | YES     | Performance Schema                                                               | NO           | NO   | NO         |
| CSV                | YES     | Stores tables as CSV files                                                       | NO           | NO   | NO         |
| ARCHIVE            | YES     | gzip-compresses tables for a low storage footprint                               | NO           | NO   | NO         |
| MEMORY             | YES     | Hash based, stored in memory, useful for temporary tables                        | NO           | NO   | NO         |
| FEDERATED          | YES     | Allows to access tables on other MariaDB servers, supports transactions and more | YES          | NO   | YES        |
| Aria               | YES     | Crash-safe tables with MyISAM heritage                                           | NO           | NO   | NO         |
+--------------------+---------+----------------------------------------------------------------------------------+--------------+------+------------+
```

最常用的是InnoDB， MySQL5.5版本之后，MySQL的默认内置存储引擎已经是InnoDB 

### MySQL各存储引擎比较？

**MyISAM和InnoDB的区别：**

1. InnoDB支持事务，MyISAM不支持。
   对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；
2. InnoDB支持外键约束，而MyISAM不支持。
3. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快。
5. Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高；5.7以后的InnoDB支持全文索引了。
6. InnoDB支持表、行级锁(默认)，而MyISAM支持表级锁。
7. InnoDB表必须有主键（用户没有指定的话会自己找或生产一个主键），而Myisam可以没有。
8. Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI。
9. InnoDB读写阻塞与事务隔离级别相关，MyISAM读写相互阻塞，写入不能读，读时不能写。
10. InnoDB从MySQL5.5后支持全文索引，从MySQL5.5.5开始为默认的数据库引擎

Innodb：frm是表定义文件，ibd是数据文件。Myisam：frm是表定义文件，myd是数据文件，myi是索引文件。

### 存储引擎文件说明？

**Innodb**：frm是表定义文件，ibd是数据文件。所有InnoDB表的数据和索引放置于同一个表空间中

表空间文件：datadir定义的目录下
 数据文件：ibddata1, ibddata2, ...

每个表单独使用一个表空间存储表的数据和索引
两类文件放在对应每个数据库独立目录中

- 数据文件(存储数据和索引)：tb_name.ibd 
- 表格式定义：tb_name.frm

启用：innodb_file_per_table=ON  (MariaDB 5.5以后版是默认值)

**Myisam**：frm是表定义文件，myd是数据文件，myi是索引文件。

- tbl_name.frm 表格式定义
- tbl_name.MYD 数据文件
- tbl_name.MYI 索引文件

### 适用场景

#### MyISAM

只读（或者写较少）、表较小（可以接受长时间进行修复操作）

#### InnoDB



## 索引

Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率，并且可以提高范围查询的效率，并且B+树里的元素也是有序的。 

### InnoDB和MyISAM引擎的B+树索引

通常我们认为B+树的非叶子节点不存储数据，只有叶子节点才存储数据；而B树的非叶子和叶子节点都会存储A据，会导致非叶子节点存储的索引值会更少，树的高度相对会比B+树高，平均的I/O效率会比较低，所以使用B+树作为索引的数据结构，再加上B+树的叶子节点之间会有指针相连，也方便进行范围查找。 

对于B+树在MyISAM中来说， **MyISAM中叶子节点的数据区域存储的是数据记录的地址**  MyISAM存储引擎在使用索引查询数据时，会先根据索引查找到数据地址，再根据地址查询到具体的数据。并且主键索引和辅助索引没有太多区别。 

Innodb中的主键索引和实际数据时绑定在一起的，也就是说Innodb的一个表一定要有主键索引，如果一个表没有手动建立主键索引，Innodb会查看有没有唯一索引，如果有则选用唯一索引作为主键索引，如果连唯一索引也没有，则会默认建立一个隐藏的主键索引（用户不可见）。另外，Innodb的主键索引要比MyISAM的主键索引查询效率要高（少一次磁盘IO），并且比辅助索引也要高很多。所以，我们在使用Innodb作为存储引擎时，我们最好：

1. 手动建立主键索引
2. 尽量利用主键索引查询



### B+树为什么一个节点为1页（16k）就够了？

对着上面Mysql中Innodb中对B+树的实际应用（主要看主键索引），可以发现B+树中的一个节点存储的内容是：

- 非叶子节点：主键+指针
- 叶子节点：数据

那么，假设我们一行数据大小为1K，那么一页就能存16条数据，也就是一个叶子节点能存16条数据；再看非叶子节点，假设主键ID为bigint类型，那么长度为8B，指针大小在Innodb源码中为6B，一共就是14B，那么一页里就可以存储16K/14=1170个(主键+指针)，那么一颗高度为2的B+树能存储的数据为：117016=18720条，一颗高度为3的B+树能存储的数据为：11701170*16=21902400（千万级条）。所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。所以也就回答了我们的问题，1页=16k这么设置是比较合适的，是适用大多数的企业的，当然这个值是可以修改的，所以也能根据业务的时间情况进行调整。

### 索引面试题



##### Hash索引和B+树所有有什么区别或者说优劣呢?

首先要知道**Hash索引和B+树索引的底层实现原理**:

hash索引底层就是hash表,进行查找时,调用一次hash函数就可以获取到相应的键值,之后进行回表查询获得实际数据.B+树底层实现是多路平衡查找树.对于每一次的查询都是从根节点出发,查找到叶子节点方可以获得所查键值,然后根据查询判断是否需要回表查询数据.

- hash索引进行等值查询更快(一般情况下),但是却无法进行范围查询 

因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.而B+树的的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似),天然支持范围. 

- hash索引不支持使用索引进行排序,原理同上.
- hash索引不支持模糊查询以及多列索引的最左前缀匹配.原理也是因为hash函数的不可预测.**AAAA**和**AAAAB**的索引没有相关性.
- hash索引任何时候都避免不了回表查询数据,而B+树在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.
- hash索引虽然在等值查询上较快,但是不稳定.性能不可预测,当某个键值存在大量重复的时候,发生hash碰撞,此时效率可能极差.而B+树的查询效率比较稳定,对于所有的查询都是从根节点到叶子节点,且树的高度较低.

##### B+ Tree索引和Hash索引区别？

- 哈希索引适合等值查询，但是无法进行范围查询 

- 哈希索引没办法利用索引完成排序 

- 哈希索引不支持多列联合索引的最左匹配规则 

- 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题
-  而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描 

#####  **B+ Tree的叶子节点都可以存哪些东西？** 

InnoDB的B+ Tree可能存储的是整行数据，也有可能是主键的值 

 **两者有什么区别** ？

在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引。而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引 

在B+树的索引中,叶子节点可能存储了当前的key值,也可能存储了当前的key值以及整行的数据,这就是聚簇索引和非聚簇索引.  在InnoDB中,只有主键索引是聚簇索引,如果没有主键,则挑选一个唯一键建立聚簇索引.如果没有唯一键,则隐式的生成一个键来建立聚簇索引.

当查询使用聚簇索引时,在对应的叶子节点,可以获取到整行数据,因此不用再次进行回表查询.

##### 聚簇索引和非聚簇索引，在查询数据的时候有区别吗？

聚簇索引查询会更快 ；聚簇索引不是一种单独的索引类型，而是一种数据的存储方式，聚簇索引的顺序，就是数据在硬盘上的物理顺序。

在mysql通常聚簇索引是主键的同义词，每张表只包含一个聚簇索引(其他数据库不一定)。

##### 为什么聚簇索引查询会更快 ？

因为主键索引树的叶子节点直接就是我们要查询的整行数据了。而非主键索引的叶子节点是主键的值，查到主键的值以后，还需要再通过主键的值再进行一次查询 

聚簇索引的优点：

可以把相关数据保存在一起，如：实现电子邮箱时，可以根据用户ID来聚集数据，这样只需要从磁盘读取少量的数据页就能获取某个用户全部邮件，如果没有使用聚集索引，则每封邮件都可能导致一次磁盘IO。

数据访问更快，聚集索引将索引和数据保存在同一个btree中，因此从聚集索引中获取数据通常比在非聚集索引中查找要快。使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

聚簇索引的缺点：

聚簇数据最大限度地提高了IO密集型应用的性能，但如果数据全部放在内存中，则访问的顺序就没有那么重要了，聚集索引也没有什么优势了

插入速度严重依赖于插入顺序，按照主键的顺序插入是加载数据到innodb表中速度最快的方式，但如果不是按照主键顺序加载数据，那么在加载完成后最好使用optimize table命令重新组织一下表。

更新聚集索引列的代价很高，因为会强制innodb将每个被更新的行移动到新的位置。

基于聚集索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临页分裂的问题，当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作，页分裂会导致表占用更多的磁盘空间。聚集索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。

#####  **非主键索引(非聚簇索引)一定会查询多次吗？**

使用覆盖索引可以实现只回表一次；也就是说取决于查询语句所要求的字段是否全部命中了索引,如果全部命中了索引,那么就不必再进行回表查询.

举个简单的例子,假设我们在员工表的年龄上建立了索引,那么当进行select age from employee where age < 20的查询时,在索引的叶子节点上,已经包含了age信息,不会再次进行回表查询.

##### 覆盖索引？

覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得（查询语句所要求的字段是否全部命中了索引），不必从数据表中读取。也可以称之为实现了索引覆盖。

当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。

#####  **创建联合索引时需要做联合索引的多个字段之间的顺序是如何选择的？** 

在创建多列索引时，根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则 

#####  **在建立索引的时候,都有哪些需要考虑的因素呢?** 

 建立索引的时候一般要考虑到字段的使用频率,经常作为条件进行查询的字段比较适合.如果需要建立联合索引的话,还需要考虑联合索引中的顺序.此外也要考虑其他方面,比如防止过多的所有对表造成太大的压力.这些都和实际的表结构以及查询方式有关. 

#####  **联合索引是什么?为什么需要注意联合索引中的顺序?** 

MySQL可以使用多个字段同时建立一个索引,叫做联合索引.在联合索引中,如果想要命中索引,需要按照建立索引时的字段顺序挨个使用,否则无法命中索引.

具体原因为:

MySQL使用索引时需要索引有序,假设现在建立了"name,age,school"的联合索引,那么索引的排序为: 先按照name排序,如果name相同,则按照age排序,如果age的值也相等,则按照school进行排序.

当进行查询时,此时索引仅仅按照name严格有序,因此必须首先使用name字段进行等值查询,之后对于匹配到的列而言,其按照age字段严格有序,此时可以使用age字段用做索引查找,,,以此类推.因此在建立联合索引的时候应该注意索引列的顺序,一般情况下,将查询需求频繁或者字段选择性高的列放在前面.此外可以根据特例的查询或者表结构进行单独的调整.

#####  **MySQL 5.6中，对索引做了哪些优化？**  

 Index Condition Pushdown：索引下推， MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = 'index_condition_pushdown=off';可以将其关闭。  有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。 

#####  有什么手段可以知道查询有没有走索引？

 通过explain查看sql语句的执行计划，通过执行计划来分析索引使用情况 

 MySQL提供了explain命令来查看语句的执行计划,MySQL在执行某个语句之前,会将该语句过一遍查询优化器,之后会拿到对语句的分析,也就是执行计划,其中包含了许多信息.  可以通过其中和索引有关的信息来分析是否命中了索引,例如possilbe_key,key,key_len等字段,分别说明了此语句可能会使用的索引,实际使用的索引以及使用的索引长度. 

- 可以通过EXPLAIN来分析索引的有效性,获取查询的执行计划信息,以及用来查看查询优化器是如何执行查询的。
- EXPLAIN 用法 `EXPLAIN SELECT clause`

 EXPLAIN输出信息说明 :

| type | 关联类型或访问类型，即MySQL决定的如何去查询表中的行的方式 |
| ---- | --------------------------------------------------------- |
|      |                                                           |

| Extra | 额外信息                                                   |
| ----- | ---------------------------------------------------------- |
|       | Using index：MySQL将会使用覆盖索引，以避免访问表           |
|       | Using where：MySQL服务器将在存储引擎检索后，再进行一次过滤 |
|       | Using temporary：MySQL对结果排序时会使用临时表             |
|       | Using filesort：对结果使用一个外部索引排序                 |

- type列显示的是访问类型，其值有多个。是较为重要的一个指标，结果值从好到坏依次是: `system > const > eq_ref > ref > fulltext >  ref_or_null > index_merge > unique_subquery > index_subquery  > range > index > ALL`
- 一般来说，得保证查询至少达到range级别，最好能达到ref



type列每个值的意义:

| 值     | 意义                                                         |
| ------ | ------------------------------------------------------------ |
| All    | 最坏的情况,全表扫描                                          |
| index  | 和全表扫描一样。只是扫描表的时候按照索引次序进行而不是行。主要优点就是避免了排序, 但是开销仍然非常大。如在Extra列看到Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要小很多 |
| range  | 范围扫描，一个有限制的索引扫描。key 列显示使用了哪个索引。当使用=、 <>、>、>=、<、<=、IS NULL、<=>、BETWEEN 或者 IN 操作符,用常量比较关键字列时,可以使用 range |
| ref    | 一种索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一性索引或唯一性索引非唯一性前缀时才会发生。这个类型跟eq_ref不同的是，它用在关联操作只使用了索引的最左前缀，或者索引不是UNIQUE和PRIMARY KEY。ref可以用于使用=或<=>操作符的带索引的列。 |
| eq_ref | 最多只返回一条符合条件的记录。使用唯一性索引或主键查找时会发生 （高效） |
| const  | 当确定最多只会有一行匹配的时候，MySQL优化器会在查询前读取它而且只读取一次，因此非常快。当主键放入where子句时，mysql把这个查询转为一个常量（高效） |
| system | 这是const连接类型的一种特例，表仅有一行满足条件。            |

#####  **那么在哪些情况下会发生针对该列创建了索引但是在查询的时候并没有使用呢?**

以下情况,MySQL无法使用索引 

- 使用不等于查询,
- 列参与了数学运算或者函数
- 在字符串like时左边是通配符.类似于'%aaa'.
- 当mysql分析全表扫描比使用索引快的时候不使用索引.
- 当使用联合索引,前面一个条件为范围查询,后面的即使符合最左前缀原则,也无法使用索引.

##### 查询优化器？

一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。

在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出**成本最低的方案**。

这个成本最低的方案就是所谓的**执行计划**。优化过程大致如下：

1、根据搜索条件，找出所有可能使用的索引 

2、计算全表扫描的代价 

3、计算使用不同索引执行查询的代价 

4、对比各种执行方案的代价，找出成本最低的那一个

## 查询缓存

### 查询缓存原理

缓存SELECT操作或预处理查询的结果集和SQL语句，当有新的SELECT语句或预处理查询语句请求，
先去查询缓存，判断是否存在可用的记录集，判断标准：当前的查询与缓存的SQL语句，是否完全一样，区分大小写

**查询缓存的优缺点：**

- 不需要对SQL语句做任何解析和执行，当然语法解析必须通过在先，直接从Query Cache中获得查询
  结果，提高查询性能
-  查询缓存的判断规则，不够智能，也即提高了查询缓存的使用门槛，降低效率
-  查询缓存的使用，会增加检查和清理Query Cache中记录集的开销

**哪些查询可能不会被缓存：**

- 查询语句中加了SQL_NO_CACHE参数
- 查询语句中含有获得值的函数，包含自定义函数，如：NOW() ，CURDATE()、GET_LOCK()、
- RAND()、CONVERT_TZ()等
- 对系统数据库的查询：mysql、information_schema 查询语句中使用SESSION级别变量或存储过程中的局部变量
- 查询语句中使用了LOCK  IN SHARE MODE、FOR UPDATE的语句，查询语句中类似SELECT …INTO 导出数据的语句
- 对临时表的查询操作；存在警告信息的查询语句；不涉及任何表或视图的查询语句；某用户只有列级别权限的查询语句
- 事务隔离级别为Serializable时，所有查询语句都不能缓存

**查询缓存相关的服务器变量：**

- **query_cache_min_res_unit**：查询缓存中内存块的最小分配单位，默认4k，较小值会减少浪费，
  但会导致更频繁的内存分配操作，较大值会带来浪费，会导致碎片过多，内存不
- **query_cache_limit**：单个查询结果能缓存的最大值，默认为1M，对于查询结果过大而无法缓存的
  语句，建议使用SQL_NO_CACHE
- **query_cache_size**：查询缓存总共可用的内存空间；单位字节，必须是1024的整数倍，最小值
  40KB，低于此值有警报
- **query_cache_wlock_invalidate**：如果某表被其它的会话锁定，是否仍然可以从查询缓存中返回结
  果，默认值为OFF，表示可以在表被其它会话锁定的场景中继续从缓存返回数据；ON则表示不允
  许
- **query_cache_type**：是否开启缓存功能，取值为ON, OFF, DEMAND

## 并发控制

### 锁机制 

几乎所有需要处理并发读/写的系统都会实现相应的锁系统，一般锁系统包含两类锁:**共享锁(shared locks)** 和**排他锁(exclusive locks)**， 或者叫**读锁(read locks)**和**写锁(write locks)**。

**乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段**  

**乐观锁**： 总是假设最好的情况，认为竞争总是不存在，每次拿数据的时候都认为不会被修改，因此不会先上锁，在最后更新的时候比较数据有无更新，可通过版本号或CAS实现。 乐观锁（optimistic locking）表现出大胆、务实的态度。使用乐观锁的前提是， 实际应用当中，发生冲突的概率比较低。他的设计和实现直接而简洁。 目前Web应用中，乐观锁的使用占有绝对优势。 

**乐观锁使用场景**： 用于读比较多的情况，避免了不必要的加锁的开销 

**悲观锁**： 总是假设最坏的情况，认为竞争总是存在，每次拿数据的时候都认为会被修改，因此每次都会先上锁。其他线程阻塞等待释放锁。 正如其名字，悲观锁（pessimistic locking）体现了一种谨慎的处事态度。其流程如下：

- 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。
- 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。
- 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
- 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

悲观锁确实很严谨，有效保证了数据的一致性，在C/S应用上有诸多成熟方案。 但是他的缺点与优点一样的明显：

- 悲观锁适用于可靠的持续性连接，诸如C/S应用。 对于Web应用的HTTP连接，先天不适用。
- 锁的使用意味着性能的损耗，在高并发、锁定持续时间长的情况下，尤其严重。 Web应用的性能瓶颈多在数据库处，使用悲观锁，进一步收紧了瓶颈。
- 非正常中止情况下的解锁机制，设计和实现起来很麻烦，成本还很高。
- 不够严谨的设计下，可能产生莫名其妙的，不易被发现的， 让人头疼到想把键盘一巴掌碎的死锁问题。

总体来看，悲观锁不大适应于Web应用。

**悲观锁使用场景**：用于写比较多的情况，避免了乐观锁不断重试从而降低性能 

**注意**：乐观锁不能与数据库中的读锁、写锁、行级锁和表级锁等混为一谈。

**锁粒度(Lock Granularity)**：一种提高共享资源的并发性的做法是让资源具有更多的选择性，或者说以更小的粒度来区分资源；只对包含 需要改变的数据的部分进行加锁，而不是锁定整个资源块。但是锁是需要占用系统资源，需要开销的机制； 每个锁操作如:获取锁、检查某个锁是否是可用、释放锁等多种都会有额外开销。如果系统花费大量资源 在处理锁机制上而不实实在在的存储数据，那就会适得其反，拖累系统。 

- 行级锁：InnoDB存储引擎提供到行级别的锁机制，也就是可以针对某个表的某个行或者某些行施加锁。
- 表级锁：MyISAM存储引擎提供到表级别的锁机制，也就是可以针对某个表施加锁。
- 另外在MySQL中支持MVCC:Multiversion Concurrency Control，其允许多个操作执行在某个表的同一行。

### MVCC

可以认为MVCC是行级锁的一个变种，它能在大多数情况下避免加锁操作，因此开销更低。无论怎样实现，它们大都实现了非阻塞的读操作，写操作也只锁定指定的行。MVCC是通过保存数据在某一个时间点的快照来实现的，也就是说无论事务执行多久，每个事务看到的数据都是一致的。

 MVCC（多版本并发控制机制）只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其 他两个隔离级别都和MVCC不兼容,因为READUNCOMMITTED总是读取最新的数据行，而不是符合当前 事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁 

### 事务



### 隔离级别

| 隔离级别         | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| READ UNCOMMITTED | 可读取到未提交数据，产生脏读(Dirty reads)                    |
| READ COMMITTED   | 可读取到提交数据，但未提交数据不可读，产生不可重复读(Non-repeatable reads)，即可读取到多个提交数据，导致每次读取数据不一致 |
| REPEATABLE READ  | 可重复读，多次读取数据都一致，产生幻读(Phantom reads)，即读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改前的旧数据。此为MySQL默认设置 |
| SERIALIZABLE     | 可串行化，未提交的读事务阻塞修改事务（加读锁，但不阻塞读事务），或者未提交的修改事务阻塞读事务（加写锁，其它事务的读，写都不可以执行）。会导致并发性能差 |

服务器变`tx_isolation`指定，默认为REPEATABLE-READ，可在GLOBAL和SESSION级进行设置 `SET tx_isolation='READ-UNCOMMITTED|READ-COMMITTED|REPEATABLE-READ|SERIALIZABLE'` 

### MySQL并发控制面试题

####  什么是事务?

理解什么是事务最经典的就是转账的栗子,相信大家也都了解,这里就不再说一边了.

事务是一系列的操作,他们要符合ACID特性.最常见的理解就是:事务中的操作要么全部成功,要么全部失败.但是只是这样还不够的.

####  ACID是什么?可以详细说一下吗?

**A=Atomicity**

原子性,就是上面说的,要么全部成功,要么全部失败.不可能只执行一部分操作.

**C=Consistency**

系统(数据库)总是从一个一致性的状态转移到另一个一致性的状态,不会存在中间状态.

**I=Isolation**

隔离性: 通常来说:一个事务在完全提交之前,对其他事务是不可见的.注意前面的通常来说加了红色,意味着有例外情况.

**D=Durability**

持久性,一旦事务提交,那么就永远是这样子了,哪怕系统崩溃也不会影响到这个事务的结果.

####  同时有多个事务在进行会怎么样呢?

多事务的并发进行一般会造成以下几个问题:

- 脏读: A事务读取到了B事务未提交的内容,而B事务后面进行了回滚.
- 不可重复读: 当设置A事务只能读取B事务已经提交的部分,会造成在A事务内的两次查询,结果竟然不一样,因为在此期间B事务进行了提交操作.
- 幻读: A事务读取了一个范围的内容,而同时B事务在此期间插入了一条数据.造成"幻觉".

####  怎么解决并发带来的问题呢?MySQL的事务隔离级别了解吗?

 MySQL的四种隔离级别如下: 

**未提交读(READ UNCOMMITTED)** 

这就是上面所说的例外情况了,这个隔离级别下,其他事务可以看到本事务没有提交的部分修改.因此会造成脏读的问题(读取到了其他事务未提交的部分,而之后该事务进行了回滚).这个级别的性能没有足够大的优势,但是又有很多的问题,因此很少使用.

**已提交读(READ COMMITTED)** 

其他事务只能读取到本事务已经提交的部分.这个隔离级别有 不可重复读的问题,在同一个事务内的两次读取,拿到的结果竟然不一样,因为另外一个事务对数据进行了修改. 

 **REPEATABLE READ(可重复读)** 

可重复读隔离级别解决了上面不可重复读的问题(看名字也知道),但是仍然有一个新问题,就是 幻读,当你读取id> 10  的数据行时,对涉及到的所有行加上了读锁,此时例外一个事务新插入了一条id=11的数据,因为是新插入的,所以不会触发上面的锁的排斥,那么进行本事务进行下一次的查询时会发现有一条id=11的数据,而上次的查询操作并没有获取到,再进行插入就会有主键冲突的问题. 

 **SERIALIZABLE(可串行化)** 

这是最高的隔离级别,可以解决上面提到的所有问题,因为他强制将所以的操作串行执行,这会导致并发性能极速下降,因此也不是很常用. 

####  **Innodb使用的是哪种隔离级别呢?** 

 InnoDB默认使用的是可重复读隔离级别. 

####  **对MySQL的锁了解吗?** 

当数据库有并发事务的时候,可能会产生数据的不一致,这时候需要一些机制来保证访问的次序,锁机制就是这样的一个机制.就像酒店的房间,如果大家随意进出,就会出现多人抢夺同一个房间的情况,而在房间上装上锁,申请到钥匙的人才可以入住并且将房间锁起来,其他人只有等他使用完毕才可以再次使用.

####  MySQL都有哪些锁呢?

从锁的类别上来讲,有共享锁和排他锁.

**共享锁:** 又叫做**读锁**. 当用户要进行数据的读取时,对数据加上共享锁.共享锁可以同时加上多个.

**排他锁**: 又叫做**写锁**. 当用户要进行数据的写入时,对数据加上排他锁.排他锁只可以加一个,他和其他的排他锁,共享锁都相斥.

用上面的例子来说就是用户的行为有两种,一种是来看房,多个用户一起看房是可以接受的. 一种是真正的入住一晚,在这期间,无论是想入住的还是想看房的都不可以.

锁的粒度取决于具体的存储引擎**,InnoDB实现了行级锁,页级锁,表级锁.**MyISAM锁粒度只到表级锁

他们的加锁开销从大大小,并发能力也是从大到小.

## 主从复制

**主从复制，一主多从，主库提供读写功能，从库提供写功能**。当一个事务在master 提交成功时，会把binlog文件同步到从库服务器上落地为relay log给slave端执行，这个过程主库是不考虑从库是否有接收到binlog文件，有可能出现这种情况，当主库commit一个事务后，数据库发生宕机，刚好它的binlog还没来得及传送到slave端，这个时候选任何一个slave端都会丢失这个事务，造成数据不一致情况。 为了避免出现主从数据不一致的情况，MySQL引入了半同步复制，添加多了一个**从库反馈机制**，这个有两种方式设置：

- 主库执行完事务后，同步binlog给从库，从库ack反馈接收到binlog，主库提交commit，反馈给客户端，释放会话；
- 主库执行完事务后，主库提交commit ，同步binlog给从库，从库ack反馈接收到binlog，反馈给客户端，释放会话；

**缺点**：

- 写操作集中在MASTER服务器上；

- MASTER宕机后，需要人为选择新主并重新给其他的slave端执行change master（可自行写第三方工具实现，但是mysql的复制就是没提供，所以也算是弊端）

 于是乎，官方感应到民间怨气以及业界压力，于2016年12月12日正式发布了MySQL Group Replication

**那么，MySQL Group Replication可以提供哪些功能呢？**

- 多主，在同一个group里边的所有实例，每一个实例可以执行写操作，也就是每个实例都执行Read-Write
  - 注意一点，多主情况下，当执行一个事务时，需要确保同个组内的每个实例都认可这个事务无冲突异常，才可以commit，如果设置的是单主，其他实例ReadOnly，则不需要进行上面的判断
  - 多主情况下，事务并发冲突问题就凸显出来了，如何避免呢？数据库内部有一个认证程序，当不同实例并发对同一行发起修改，在同个组内广播认可时，会出现并发冲突，那么会按照先执行的提交，后执行的回滚
- 弹性，同个Group Replication中，节点的加入或者移除都是自动调整；如果新加入一个节点，该节点会自动从Group的其他节点同步数据，直到与其他节点一致；如果移除一个节点，那么剩下的实例会自动更新，不再向这个节点广播事务操作，当然，这里要注意，假设一个Group的节点有n个（max(n)=9，同个Group最多节点数为9），移除或者宕机的节点数应该小于等于 floor((n-1)/2) ，注意是向下取整；如果是单主模式，宕机的是单主，则人为选择新主后，其他节点也会自动从新主同步数据。

**故障探测（ Failure Detection）：**

Group Replication中有一个故障检测机制，会提供某些节点可能死掉的信息，然后广播给同一个Group的各个节点，如果确定宕机，那么组内的节点就会与它隔离开来，该节点即无法同步其他节点的传送过来的binlog events，也无法执行任何本地事务。

**配置MGR数据库要求**：

**innodb引擎**

  为什么需要使用innodb引擎呢？在MySQL Group Replication中，事务以乐观形式执行，但是在提交时检查冲突，如果存在冲突，则会在某些实例上回滚事务，保持各个实例的数据一致性，那么，这就需要使用到 事务存储引擎，同事Innodb提供一些额外的功能，可以更好的管理和处理冲突，所以建议 业务使用表格使用inndb存储引擎，类似于系统表格mysql.user使用MyISAM引擎的表格，因为极少修改及添加，极少出现冲突情况。

**主键**

  每个需要复制的表格都必须定义一个显式主键，注意跟隐式主键区分（使用Innodb引擎的表格，如果没有指定主键，默认选择第一个非空的唯一索引作为主键，如果没有，则自动创建一个6个字节的rowid隐式主键）。这个主键能在冲突发生时启动极其重要的作用，同时，能够有效提高relay log的执行效率。

**隔离级别**

  官网建议使用READ COMMITTED级别，除非应用程序依赖于REPLEATABLE READ，RC模式下没有GAP LOCK，比较好支持Innodb本身的冲突检测机制何组复制的内部分布式检测机制一起协同工作。不支持SERIALIZABLE隔离级别。

 **外键**

  不建议使用级联外键，如果旧库本身有外键，业务上无法去除并且使用的是多主模式，那么，请配置 group_replication_enforce_update_everywhere_check ，强制检查每个组成员的级联检查，避免多主模式下执行级联操作造成的检测不到的冲突。



## 备份和恢复



## 集群



## MySQL最佳实践

### 面试题

#### 建表时为什么要尽量设定一个主键?

主键是数据库确保数据行在整张表唯一性的保障,即使业务上本张表没有主键,也建议添加一个自增长的ID列作为主键.设定了主键之后,在后续的删改查的时候可能更加快速以及确保操作数据范围安全. 

#### 主键使用自增ID还是UUID?

推荐使用自增ID,不要使用UUID.因为在InnoDB存储引擎中,主键索引是作为聚簇索引存在的,也就是说,主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序),如果主键索引是自增ID,那么只需要不断向后排列即可,如果是UUID,由于到来的ID与原来的大小不确定,会造成非常多的数据插入,数据移动,然后导致产生很多的内存碎片,进而造成插入性能的下降.

总之,在数据量大一些的情况下,用自增主键性能会好一些.

关于主键是聚簇索引,**如果没有主键,InnoDB会选择一个唯一键来作为聚簇索引,如果没有唯一键,会生成一个隐式的主键.** 

####  **如果要存储用户的密码散列,应该使用什么字段进行存储?** 

 密码散列,盐,用户身份证号等固定长度的字符串应该使用char而不是varchar来存储,这样可以节省空间且提高检索效率. 



# 八. Ansible



# 九. HTTP协议与HTTPD



# 十. LAMP/LNMP

## apache的几种工作模式？

# 十一. LVS

**集群**：同一个业务系统，部署在多台服务器上。集群中，每一台服务器实现的功能没有差别，数据和代码都是一样的
**分布式**：一个业务被拆成多个子业务，或者本身就是不同的业务，部署在多台服务器上。分布式中，每一台服务器实现的功能是有差别的，数据和代码也是不一样的，分布式每台服务器功能加起来，才是完整的业务。

一句话：**分布式是通过缩短单个任务的执行时间来提高效率，集群是通过增加单位时间内执行的任务数量来提高效率。**

**查看内核对LVS的支持**

```bash
grep -i -C 10 ipvs /boot/config-$(uname -r)
```

## LVS 相关术语

`VS`：Virtual Server，Director Server(DS), Dispatcher(调度器)，Load Balancer
`RS`：Real Server(lvs), upstream server(nginx), backend server(haproxy)
`CIP`：Client IP
`VIP`：Virtual serve IP VS 外网的 IP
`DIP`：Director IP VS 内网的 IP
`RIP`：Real server IP
访问流程：`CIP <--> VIP == DIP <--> RIP`

## LVS 集群的工作模式

LVS 有四种工作模式

- lvs-nat：修改请求报文的目标 IP,多目标 IP 的 DNAT
- lvs-dr：操纵封装新的 MAC 地址
- lvs-tun：在原请求 IP 报文之外新加一个 IP 首部
- lvs-fullnat：修改请求报文的源和目标 IP

### LVS 的 NAT 工作模式

**vs-nat**：本质是多目标 IP 的 DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的 RS 的 RIP 和 PORT 实现转发，特点：

- （1）RIP 和 DIP 应在同一个 IP 网络，且应使用私网地址；RS 的网关要指向 DIP

- （2）请求报文和响应报文都必须经由 Director 转发，Director 易于成为系统瓶颈
- （3）支持端口映射，可修改请求报文的目标 PORT
- （4）VS 必须是 Linux 系统，RS 可以是任意 OS 系统 

### LVS 的 DR 模式

**LVS-DR**：Direct Routing，直接路由，LVS 默认模式,应用最广泛,通过为请求报文重新封装一个 MAC 首部进行转发，源 MAC 是 DIP 所在的接口的 MAC，目标 MAC 是某挑选出的 RS 的 RIP 所在接口的 MAC 地址；源IP/PORT，以及目标 IP/PORT 均保持不变 

**DR 模式的特点**：

1. Director 和各 RS 都配置有 VIP

2. 确保前端路由器将目标 IP 为 VIP 的请求报文发往 Director
   需要在前端网关做静态绑定 VIP 和 Director 的 MAC 地址
   在 RS 上使用 arptables 工具

   ```bash
   arptables -A IN -d $VIP -j DROP
   arptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP
   ```

   在 RS 上修改内核参数以限制 arp 通告及应答级别[^1]

   ```bash
   /proc/sys/net/ipv4/conf/all/arp_ignore
   /proc/sys/net/ipv4/conf/all/arp_announce
   ```

3. RS 的 RIP 可以使用私网地址，也可以是公网地址；RIP 与 DIP 在同一 IP网络；RIP 的网关不能指向 DIP，以确保响应报文不会经由 Director

4. RS 和 Director 要在同一个物理网络

5. 请求报文要经由 Director，但响应报文不经由 Director，而由 RS 直接发往 Client

6. 不支持端口映射（端口不能修败）

7. RS 可使用大多数 OS 系统

### LVS 的 TUN 模式

**转发方式**：不修改请求报文的 IP 首部（源 IP 为 CIP，目标 IP 为 VIP），而在原 IP 报文之外再封装一个 IP 首部（源 IP 是 DIP，目标 IP 是 RIP），将报文发往挑选出的目标 RS；RS 直接响应给客户端(源 IP 是 VIP，目标 IP 是 CIP) 

**TUN 模式特点**：

1. DIP, VIP, RIP 可以是公网地址
2. RS 的网关一般不能指向 DIP
3. 请求报文要经由 Director，但响应不经由 Director
4. 不支持端口映射
5. RS 的 OS 须支持隧道功能

### LVS 的 FULLNAT 模式

通过同时修改请求报文的源 IP 地址和目标 IP 地址进行转发
: CIP --> DIP
: VIP --> RIP

**fullnat 模式特点**：

1. VIP 是公网地址，RIP 和 DIP 是私网地址，且通常不在同一 IP 网络；因此，
   RIP 的网关一般不会指向 DIP
2. RS 收到的请求报文源地址是 DIP，因此，只需响应给 DIP；但 Director 还
   要将其发往 Client
3. 请求和响应报文都经由 Director
4. 支持端口映射

**注意**：此类型 kernel 默认不支持

 **lvs-nat 与 lvs-fullnat对比**

- 请求和响应报文都经由 Director
- lvs-nat：RIP 的网关要指向 DIP
- lvs-fullnat：RIP 和 DIP 未必在同一 IP 网络，但要能通信 

 **lvs-dr 与 lvs-tun**

- 请求报文要经由 Director，但响应报文由 RS 直接发往 Client
- lvs-dr：通过封装新的 MAC 首部实现，通过 MAC 网络转发
- lvs-tun：通过在原 IP 报文外封装新 IP 头实现转发，支持远距离通信 



## LVS 调度算法

### 静态调度算法

#### Round-Robin Scheduling

**循环调度算法**：该调度算法是 LVS 最简单的调度策略，其将每个传入的请求发送到其列表的下一个服务器。例如：在三个服务器的集群中(A、B 和 C 服务器)，请求 1将被 调度到服务器 A，请求 2 将被调度到服务器 B，请求 3 将被 C 服务器处理，请求 4 又被调度到服务器 A。从而让集群中的服务器循环的提供服务，该调度策略平等对待所有服务器，其不考虑到来的连接或请求数量和服务器的响应时间(或是负载情况)，其性能高于传统的 DNS 轮询。 

#### Weighted Round-Robin Scheduling

**加权轮询调度算法**：该调度策略旨在处理不同的性能的服务器在接收请求和处理请求时的权重呵呵优先顺序。在调度期间，每个服务器的性能有差异，各自会被分配不同的权重值，一个表示处理能力的整数值。权重较大的服务器比权重小的服务器优先处理新连接，权重较大的服务器也比权重较小的服务器获得更多的连接，权重相同的服务器获得相同的连接数。例如：RS 服务器分别为 A、B 和 C，它们分别有权重4、3 和 2，那么一个比较理想的调度序列会是 AABABCABC，可以看到在三次轮询过程中，不同权重的 RS 被分配了不同的连接数，但是整个过程中各自总的处理连接比例接近 4:3:2(A 处理了 4 次，B 处理了 3 次，C 处理了 2 次)。 

在加权轮询调度的实现中，在管理员修改 VS 的服务器调度策略后，会根据具体的配置权重来生成调度序列。基于该序列以轮询调度方式将不同的网络连接定向到后端不同的 RS 服务器。

当后端 RS 服务器的处理性能不一时，此算法是比单纯的轮询调度算法优异的。但是，如果有不间断的高负载的请求到来时，可能造成各服务器的动态负载严重不均衡。也就是说，可能会有很大部分的高负载请求都被调度到相同的 RS 上。此时，该 RS的复制将会很高。

而实际上，轮询是加权轮询策略的特例，即是加权轮询的权重值都为 1 的情况。

#### Destination Hashing Scheduling

**目标地址哈希调度**： 目标地址散列调度（Destination Hashing Scheduling）算法也是针对目标IP地址的负载均衡，但它是一种静态映射算法，通过一个散列（Hash）函数将一个目标IP地址映射到一台服务器。  目标地址散列调度算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。该调度策略的典型使用场景是正向代理缓存场景中的负载均衡，如：宽带运营商 

#### Source Hashing Scheduling

**源地址散列调度**（Source Hashing Scheduling）算法正好与目标地址散列调度算法相反，它根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同。

 在实际应用中，源地址散列调度和目标地址散列调度可以结合使用在防火墙集群中，它们可以保证整个系统的唯一出入口

### 动态调度算法

#### Least-Connection Scheduling

**最少连接调度算法**：该调度策略将网络连接调度给建立连接数量最少的 RS 服务器。该调度算法会动态的记录各服务器的活动连接数。如果后端的一群 RS 服务器的处理性能相近，那么最少连接调度策略有助于在请求的负载有大幅变化时平滑分配负载。VS 将把请求定向到有最少的活动连接的 RS。乍一看，该调度策略应该可以在服务器的处理性能各不相同的情况下表现良好，因为处理性能高的服务器会接到更多的请求并处理。然而由于 TCP 协议的`TIME_WAIT`状态导致了其表现并不好。TCP 定义的`TIME_WAIT`状态为 2 分钟，在这两分钟内某个繁忙的站点可能已经收到了好几千个请求。例如：RS-A 的处理性能是 RS-B 的两倍，RS-A 可能已经按照正常的速度完成了这些请求并将它们保持在了`TIME_WAIT`状态(也就是在 2 分钟内完成了分配的请求)，而 RS-B 正挣扎着完成分配到自己的好几千的请求，在这种情况下就没法均衡负载了。 

#### Weighted Least-Connection Scheduling

**加权的最少连接调度算法**：该调度策略允许为每个 RS 服务器分配一个性能权重值。具有较高权重值的服务器在任何时候都将接收到较大百分比的活动连接。VS 管理员可以给每个 RS 服务器分配一个权重值，网络连接会被调度到每个 RS 服务器并且每个服务器的当前活动连接数的百分比与其权重成比例。

加权的最少连接调度算法相比最少连接算法需要额外的除法来区分不同比例。为了在服务器处理能力接近相同的情况下最小化调度工作的开销，才有了非加权和加权的最少连接算法。

#### Locality-Based Least-Connection Scheduling

**基于位置的最少连接调度算法**：该调度策略专用于目的 IP 的负载均衡。一般被用于缓存集群。该算法通常会将到某个 IP 地址的数据包定向到负责处理其的服务器，前提是该服务器是活动的并且负载不高。如果该服务过载(活动连接数大于其权重)并且有一个服务器目前只有一半的负载，那就会将加权的最少连接服务器(一般负载的服务器)分配给该 IP。 

#### Locality-Based Least-Connection with Replication Scheduling

基于位置的带复制的最少连接调度算法：该调度策略也用于目的 IP 的负载均衡。一般用于缓存集群。在以下方面其和 LBLC 调度策略不同：调度服务器 LVS 会维护某个目的 IP 到可能为其提供服务的服务器节点的映射。发往目标 IP 的请求将被调度到该目标 IP 对应的服务器节点集中拥有最少连接的节点。如果该服务器集的节点均过载，那么 LVS 会在整个集群中挑选一个最少连接的节点加入到这个服务器集(可能为该目标IP 服务的节点集合)。 

#### Shortest Expected Delay Scheduling

最短期望时延调度算法：该算法将网络连接调度分配给预期最小时延的服务器。发送到集群中的第 i 个节点最小时延可表示为：(Ci + 1)/Ui。Ci 是第 i 个服务器的连接数，Ui 是第 i 个服务器的权重。 

#### Never Queue Scheduling

不排队算法： 该调度策略在有空闲的服务器时将请求调度到该空闲服务器。如果没有空闲服务器，请求将被调度到最少期望时延的节点(SED)。 

### 内核版本 4.15 版本后新增调度算法：FO 和 OVF

**FO(Weighted Fail Over)调度算法**，在此 FO 算法中，会遍历虚拟服务所关联的真实服务
器链表，找到还未过载(未设置 IP_VS_DEST_F_OVERLOAD 标志)的且权重最高的真实服务器，
进行调度
**OVF(Overflow-connection)调度算法**，基于真实服务器的活动连接数量和权重值实现。
将新连接调度到权重值最高的真实服务器，直到其活动连接数量超过权重值位置，之后调
度到下一个权重值最高的真实服务器,在此 OVF 算法中，遍历虚拟服务相关联的真实服务器
链表，找到权重值最高的可用真实服务器。一个可用的真实服务器需要同时满足以下条件：

- 未过载（未设置 IP_VS_DEST_F_OVERLOAD 标志）
- 真实服务器当前的活动连接数量小于其权重值
- 其权重值不为零



#### ipvsadm

**ipvsadm 工具用法**

```bash
# 管理集群服务
ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask]
[--pe persistence_engine] [-b sched-flags]
ipvsadm -D -t|u|f service-address # 删除
ipvsadm –C # 清空
ipvsadm –R # 重载
ipvsadm -S [-n]  # 保存
# 管理集群中的RS
ipvsadm -a|e -t|u|f service-address -r server-address [options]
ipvsadm -d -t|u|f service-address -r server-address
ipvsadm -L|l [options]
ipvsadm -Z [-t|u|f service-address]
```

保存规则：建议保存至/etc/sysconfig/ipvsadm

```bash
ipvsadm-save > /PATH/TO/IPVSADM_FILE
ipvsadm -S > /PATH/TO/IPVSADM_FILE
systemctl stop ipvsadm.service
```

重新载入

```bash
ipvsadm-restore < /PATH/FROM/IPVSADM_FILE
systemctl restart ipvsadm.service
```

#### LVS 借助三方软件实现高可用

如果 LVS 服务器宕机时，整个集群的服务将终止
: 当整个集群的调度由一台 LVS 主机负负责时，Director 不可用时，整个集群的服务
将会终止，这是常见的 SPOF 单点故障，所以在生产中不会只用一台 LVS，而是使用其它
技术实现 LVS 调度器的高可用，比如：keepalived heartbeat 或者 corosync

当某 RS 宕机时，Director 还会往其调度请求
: 如果只使用 LVS 进行调度，当某 RS 宕机时，Director 还会往其调度请求。这回造成部分请
求未被处理，还会使得 LVS 付出额外无用的开销。
: 解决方案：通过某些方法使得 Director 可以对各个 RS 进行健康状态监测，失败时自动禁用，
恢复后自动添加到集群。

常用的高可用解决方案
: keepalived
: heartbeat/corosync
: ldirectord

检测 RS 的方式
: 网络层检测，icmp
: 传输层检测，端口探测
: 应用层检测，请求某关键资源

RS 全部宕机或者是维护时：可以使用 LVS 调度器来响应客户，告知大致情况，此时的服务称为：
sorry server(道歉服务)

# 十二. Nginx



# 十三. HAProxy



# 十四. Tomcat



# 十五. ESXi

# 15.5 各种缓存

# 十六. Redis

## 1.什么是 redis?

Redis 是一个基于内存的高性能 key-value 数据库。

## 2.Reids 的特点

Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。

Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个 value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能，比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性 能消息队列服务，用他的 Set 可以做高性能的 tag 系统等等。另外 Redis 也可以对存入的 Key-Value 设置 expire 时间，因此也可以被当作一 个功能加强版的 memcached 来用。

Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。

## 3.使用 redis 有哪些好处？

- (1) 速度快，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)
- (2) 支持丰富数据类型，支持 string，list，set，sorted set，hash

```ruby
1）String

常用命令：set/get/decr/incr/mget 等；
应用场景：String 是最常用的一种数据类型，普通的 key/value 存储都可以归为此类；
实现方式：String 在 redis 内部存储默认就是一个字符串，被 redisObject 所引用，当遇到 incr、decr 等操作时会转成数值型进行计算，此时 redisObject 的 encoding 字段为 int。
2）Hash

常用命令：hget/hset/hgetall 等
应用场景：我们要存储一个用户信息对象数据，其中包括用户 ID、用户姓名、年龄和生日，通过用户 ID 我们希望获取该用户的姓名或者年龄或者生日；
实现方式：Redis 的 Hash 实际是内部存储的 Value 为一个 HashMap，并提供了直接存取这个 Map 成员的接口。如图所示，Key 是用户 ID, value 是一个 Map。这个 Map 的 key 是成员的属性名，value 是属性值。这样对数据的修改和存取都可以直接通过其内部 Map 的 Key(Redis 里称内部 Map 的 key 为 field), 也就是通过 key(用户 ID) + field(属性标签) 就可以操作对应属性数据。当前 HashMap 的实现有两种方式：当 HashMap 的成员比较少时 Redis 为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的 HashMap 结构，这时对应的 value 的 redisObject 的 encoding 为 zipmap，当成员数量增大时会自动转成真正的 HashMap,此时 encoding 为 ht。
hash
3）List
常用命令：lpush/rpush/lpop/rpop/lrange 等；
应用场景：Redis list 的应用场景非常多，也是 Redis 最重要的数据结构之一，比如 twitter 的关注列表，粉丝列表等都可以用 Redis 的 list 结构来实现；
实现方式：Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis 内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。
4）Set
常用命令：sadd/spop/smembers/sunion 等；
应用场景：Redis set 对外提供的功能与 list 类似是一个列表的功能，特殊之处在于 set 是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的；
实现方式：set 的内部实现是一个 value 永远为 null 的 HashMap，实际就是通过计算 hash 的方式来快速排重的，这也是 set 能提供判断一个成员是否在集合内的原因。
5）Sorted Set

常用命令：zadd/zrange/zrem/zcard 等；
应用场景：Redis sorted set 的使用场景与 set 类似，区别是 set 不是自动有序的，而 sorted set 可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择 sorted set 数据结构，比如 twitter 的 public timeline 可以以发表时间作为 score 来存储，这样获取时就是自动按时间排好序的。
实现方式：Redis sorted set 的内部使用 HashMap 和跳跃表(SkipList)来保证数据的存储和有序，HashMap 里放的是成员到 score 的映射，而跳跃表里存放的是所有的成员，排序依据是 HashMap 里存的 score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。
```

- (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
- (4) 丰富的特性：可用于缓存，消息，按 key 设置过期时间，过期后将会自动删除

## 4.redis 相比 memcached 有哪些优势？

- (1) memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型
- (2) redis 的速度比 memcached 快很多 (3) redis 可以持久化其数据

5.Memcache 与 Redis 的区别都有哪些？

- (1)、存储方式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis 有部份存在硬盘上，这样能保证数据的持久性。
- (2)、数据支持类型 Memcache 对数据类型支持相对简单。Redis 有复杂的数据类型。
- (3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。

## 6.redis 适用于的场景?

Redis 最适合所有数据 in-momory 的场景，如：

- （1）、会话缓存（Session Cache）

最常用的一种使用 Redis 的情景是会话缓存（session cache）。用 Redis 缓存会话比其他存储（如 Memcached）的优势在于：Redis 提供持久化。

- （2）、全页缓存（FPC）

除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。

- （3）、队列

Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如 Python）对 list 的 push/pop 操作。

如果你快速的在 Google 中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用 Redis 创建非常好的后端工具，以满足各种队列需求。例如，Celery 有一个后台就是使用 Redis 作为 broker，你可以从这里去查看。

- （4），排行榜/计数器

Redis 在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：

当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：

ZRANGE user_scores 0 10 WITHSCORES

Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可以在这里看到。

- （5）、发布/订阅

最后（但肯定不是最不重要的）是 Redis 的发布/订阅功能。发布/订阅的使用场景确实非常多。

## 7、redis 的缓存失效策略和主键失效机制

作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.

- 在 Redis 当中，有生存期的 key 被称为 volatile。在创建缓存时，要为给定的 key 设置生存期，当 key 过期的时候（生存期为 0），它可能会被删除。

- 1、影响生存时间的一些操作
  生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改 key 对应的 value 和使用另外相同的 key 和 value 来覆盖以后，当前数据的生存时间不同。
    　　比如说，对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用 RENAME 对一个 key 进行改名，那么改名后的 key 的生存时间和改名前一样。
    　　 RENAME 命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用 PERSIST 命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个 persistent key 。

- 2、如何更新生存时间
  可以对一个已经带有生存时间的 key 执行 EXPIRE 命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在 1ms 之内，主键失效的时间复杂度是 O（1），
    　　 EXPIRE 和 TTL 命令搭配使用，TTL 可以查看 key 的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。
    　　最大缓存配置
    　　在 redis 中，允许用户设置最大使用内存大小
    　　 server.maxmemory
    　　默认为 0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使 redis 崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。

## redis 提供 6 种数据淘汰策略：

  　　． volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
  　　． volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
  　　． volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
  　　． allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
  　　． allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
  　　． no-enviction（驱逐）：禁止驱逐数据
  　　注意这里的 6 种机制，volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的 lru、ttl 以及 random 是三种不同的淘汰策略，再加上一种 no-enviction 永不回收的策略。
  　　使用策略规则：
  　　 1、如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru
  　　 2、如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 allkeys-random

## 三种数据淘汰策略：

  　　 ttl 和 random 比较容易理解，实现也会比较简单。主要是 Lru 最近最少使用淘汰策略，设计上会对 ke y 按失效时间排序，然后取最先失效的 key 进行淘汰

## 8.为什么 redis 需要把所有数据放到内存中?

Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，redis 将会越来越受欢迎。如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。

## 9.Redis 是单进程单线程的

redis 利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销

## 10.redis 的并发竞争问题如何解决?

Redis 为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis 本身没有锁的概念，Redis 对于多个客户端连接并不存在竞争，但是在 Jedis 客户端对 Redis 进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有 2 种解决方法：

- 1.客户端角度，为保证每个客户端间正常有序与 Redis 进行通信，对连接进行池化，同时对客户端读写 Redis 操作采用内部锁 synchronized。

- 2.服务器角度，利用 setnx 实现锁。
  注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用 synchronized 也可以使用 lock；第二种需要用到 Redis 的 setnx 命令，但是需要注意一些问题。

## 11、redis 常见性能问题和解决方案：

- 1).Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master 最好不要写内存快照。

- 2).Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。

- 3).Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。

- 4). Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。

## 12.redis 事物的了解 CAS(check-and-set 操作实现乐观锁 )?

和众多其它数据库一样，Redis 作为 NoSQL 数据库也同样提供了事务机制。在 Redis 中MULTI/EXEC/DISCARD/WATCH 这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出Redis 中事务的实现特征：

- 1). 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。
- 2). 和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。
- 3). 我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为"BEGIN TRANSACTION"语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行 EXEC/DISCARD 命令来提交/回滚该事务内的所有操作。这两个 Redis 命令可被视为等同于关系型数据库中的 COMMIT/ROLLBACK 语句。
- 4). 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。
- 5). 当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis 服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用 Redis 工具包中提供的 redis-check-aof 工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动 Redis 服务器了。

## 13.WATCH 命令和基于 CAS 的乐观锁?

在 Redis 的事务中，WATCH 命令可用于提供 CAS(check-and-set)功能。假设我们通过 WATCH 命令在事务执行之前监控了多个 Keys，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 Null multi-bulk 应答以通知调用者事务执行失败。

例如，我们再次假设 Redis 中并未提供 incr 命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：
　　 val = GET mykey
　　 val = val + 1
　　 SET mykey \$val
　　以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景--竞态争用(race condition)。比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：
　　WATCH mykey
　　val = GET mykey
　　val = val + 1
　　MULTI
　　SET mykey $val
　　 EXEC
　　和此前代码不同的是，新代码在获取 mykey 的值之前先通过 WATCH 命令监控了该键，此后又将 set 命令包围在事务中，这样就可以有效的保证每个连接在执行 EXEC 之前，如果当前连接获取的 mykey 的值被其它连接的客户端修改，那么当前连接的 EXEC 命令将执行失败。这样调用者在判断返回值后就可以获悉 val 是否被重新设置成功。

## 14.使用过 Redis 分布式锁么，它是什么回事？

先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。

这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？

这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。

15.假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？

使用 keys 指令可以扫出指定模式的 key 列表。

对方接着追问：如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？

这个时候你要回答 redis 关键的一个特性：redis 的单线程的。**keys 指令会导致线程阻塞一段时间**，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，**scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了**，但是整体所花费的时间会比直接用 keys 指令长。

## 16.使用过 Redis 做异步队列么，你是怎么用的？

一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。

如果对方追问能不能生产一次消费多次呢？使用 pub/sub 主题订阅者模式，可以实现 1:N 的消息队列。

如果对方追问 pub/sub 有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。

**如果对方追问 redis 如何实现延时队列？**

我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：**使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理**。到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。

## 17.如果有大量的 key 需要设置同一时间过期，一般需要注意什么？

如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。

## 18.Redis 如何做持久化的？

bgsave 做镜像全量持久化，aof 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 aof 来配合使用。在 redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 aof 重放近期的操作指令来实现完整恢复重启之前的状态。

对方追问那如果突然机器掉电会怎样？取决于 aof 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync，比如 1s1 次，这个时候最多就会丢失 1s 的数据。

对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow。fork 是指 redis 通过创建子进程来进行 bgsave 操作，cow 指的是 copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

## 19.Pipeline 有什么好处，为什么要用 pipeline？

可以将多次 IO 往返的时间缩减为一次，前提是 pipeline 执行的指令之间没有因果相关性。使用 redis-benchmark 进行压测的时候可以发现影响 redis 的 QPS 峰值的一个重要因素是 pipeline 批次指令的数目。

## 20.Redis 的同步机制了解么？

Redis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb 文件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。

## 21.是否使用过 Redis 集群，集群的原理是什么？

Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务。

Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行分片存储。



# 十七. Docker



# 十八. Zabbix



# 十九. Gitlab&Jenkins



# 二十. ELK stack

## Elasticsearch

## Logstash

## Kibana

# 二十一. 中间件

## Zookeeper

## Kafka

## RabbitMQ

## Dubbo

# 二十二. Kubernetes



# 二十三. OpenStack

# 三十四.Django

